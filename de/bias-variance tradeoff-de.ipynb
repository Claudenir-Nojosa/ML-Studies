{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14f114e0",
   "metadata": {},
   "source": [
    "# Bias-Variance Trade-off, Overfitting und Underfitting\n",
    "\n",
    "![Capa](../Assets/bias_variance_tradeoff/capa3.png)\n",
    "\n",
    "## 1. Das grundlegende Problem\n",
    "\n",
    "Wenn wir ein Machine Learning Modell trainieren, wollen wir, dass es gut mit neuen Daten funktioniert (die es noch nie gesehen hat). Aber es gibt zwei Arten von Fehlern, die auftreten können:\n",
    "\n",
    "1. Fehler auf dem Training Set (Trainingsdaten)\n",
    "2. Fehler auf dem Test Set (neue Daten)\n",
    "\n",
    "Das ideale Modell hat niedrige Fehler bei beiden. Aber in der Praxis gibt es einen Trade-off zwischen zwei Konzepten: Bias und Variance.\n",
    "\n",
    "## 2. Was ist Bias (Verzerrung)?\n",
    "\n",
    "Bias ist der Fehler, der durch falsche Annahmen oder ein zu einfaches Modell verursacht wird.\n",
    "\n",
    "### Praktische Analogie\n",
    "\n",
    "Stellen Sie sich vor, Sie versuchen, ein Ziel mit Pfeilen zu treffen:\n",
    "- Hoher Bias = Ihre Pfeile treffen konstant weit vom Zentrum entfernt (Sie zielen falsch)\n",
    "- Niedriger Bias = Ihre Pfeile treffen im Durchschnitt nahe am Zentrum\n",
    "\n",
    "### Im Machine Learning\n",
    "\n",
    "Ein Modell mit hohem Bias:\n",
    "- Ist zu einfach, um die Muster in den Daten zu erfassen\n",
    "- Macht starke Annahmen über die Beziehung zwischen X und y\n",
    "- Führt zu Underfitting (Unteranpassung)\n",
    "\n",
    "Beispiel: Eine gerade Linie verwenden, um Daten mit einer Kurve zu modellieren\n",
    "\n",
    "![High Bias](../Assets/bias_variance_tradeoff/1.jpg)\n",
    "\n",
    "```\n",
    "Modell zu einfach!\n",
    "Erfasst nicht das echte Muster.\n",
    "```\n",
    "\n",
    "## 3. Was ist Variance (Varianz)?\n",
    "\n",
    "Variance ist der Fehler, der durch übermäßige Empfindlichkeit gegenüber Trainingsdaten verursacht wird.\n",
    "\n",
    "### Praktische Analogie\n",
    "\n",
    "Weiter mit den Pfeilen:\n",
    "- Hohe Variance = Ihre Pfeile sind überall verstreut (inkonsistent)\n",
    "- Niedrige Variance = Ihre Pfeile sind nah beieinander gruppiert (konsistent)\n",
    "\n",
    "### Im Machine Learning\n",
    "\n",
    "Ein Modell mit hoher Variance:\n",
    "- Ist zu komplex und \"merkt sich\" die Trainingsdaten\n",
    "- Passt sich zu sehr an das Rauschen in den Daten an\n",
    "- Führt zu Overfitting (Überanpassung)\n",
    "\n",
    "Beispiel: Ein Polynom 10. Grades verwenden, um einfache Daten zu modellieren\n",
    "\n",
    "![High Variance](../Assets/bias_variance_tradeoff/2.png)\n",
    "\n",
    "``` \n",
    "Modell zu komplex!\n",
    "Geht durch alle Punkte, aber \n",
    "generalisiert nicht auf neue Daten.\n",
    "```\n",
    "\n",
    "## 4. Underfitting (Unteranpassung) - Hoher Bias\n",
    "\n",
    "### Was ist das?\n",
    "\n",
    "Underfitting tritt auf, wenn das Modell zu einfach ist, um die Muster in den Daten zu erfassen.\n",
    "\n",
    "### Merkmale\n",
    "\n",
    "- Hoher Fehler auf dem Training Set\n",
    "- Hoher Fehler auf dem Test Set\n",
    "- Modell hat das grundlegende Muster der Daten nicht gelernt\n",
    "\n",
    "### Numerisches Beispiel\n",
    "\n",
    "Datensatz mit quadratischer Beziehung: $y = x^2 + \\text{Rauschen}$\n",
    "\n",
    "| x  | y (tatsächlich) |\n",
    "|----|----------|\n",
    "| 1  | 1.2      |\n",
    "| 2  | 4.1      |\n",
    "| 3  | 9.3      |\n",
    "| 4  | 16.2     |\n",
    "| 5  | 25.1     |\n",
    "\n",
    "Modell 1: Gerade Linie $h(x) = \\theta_0 + \\theta_1 x$\n",
    "\n",
    "Ergebnis:\n",
    "- Training Error: 45.2\n",
    "- Test Error: 47.8\n",
    "\n",
    "Warum? Eine gerade Linie kann die Krümmung der Daten nicht erfassen!\n",
    "\n",
    "### Wie erkennt man Underfitting?\n",
    "\n",
    "1. Hoher Training Error (ungefähr 40-50% Fehler)\n",
    "2. Test Error ähnlich wie Training (kleiner Unterschied)\n",
    "3. Lernkurve: beide Fehler bleiben hoch, auch mit mehr Daten\n",
    "\n",
    "## 5. Overfitting (Überanpassung) - Hohe Variance\n",
    "\n",
    "### Was ist das?\n",
    "\n",
    "Overfitting tritt auf, wenn das Modell zu komplex ist und die Trainingsdaten \"auswendig lernt\", einschließlich des Rauschens.\n",
    "\n",
    "### Merkmale\n",
    "\n",
    "- Niedriger Fehler auf dem Training Set\n",
    "- Hoher Fehler auf dem Test Set\n",
    "- Modell hat auswendig gelernt statt zu lernen\n",
    "\n",
    "### Numerisches Beispiel\n",
    "\n",
    "Datensatz mit quadratischer Beziehung: $y = x^2 + \\text{Rauschen}$\n",
    "\n",
    "| x  | y (Training) | y (Test) |\n",
    "|----|------------|----------|\n",
    "| 1  | 1.2        | 0.9      |\n",
    "| 2  | 4.1        | 3.8      |\n",
    "| 3  | 9.3        | 9.5      |\n",
    "| 4  | 16.2       | 15.7     |\n",
    "| 5  | 25.1       | 25.4     |\n",
    "\n",
    "Modell 2: Polynom 10. Grades $h(x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2 + ... + \\theta_{10} x^{10}$\n",
    "\n",
    "Ergebnis:\n",
    "- Training Error: 0.01 (praktisch null!)\n",
    "- Test Error: 152.7 (explodiert!)\n",
    "\n",
    "Warum? Das Modell passte sich perfekt an die Trainingsdaten an (einschließlich Rauschen), generalisiert aber nicht auf neue Daten.\n",
    "\n",
    "### Wie erkennt man Overfitting?\n",
    "\n",
    "1. Sehr niedriger Training Error (ungefähr 1-5% Fehler)\n",
    "2. Sehr hoher Test Error (10x größer als Training)\n",
    "3. Große Lücke zwischen Training und Test Error\n",
    "4. Lernkurve: Training fällt weiter, Test beginnt zu steigen\n",
    "\n",
    "## 6. Das ideale Modell - Just Right (Goldilocks)\n",
    "\n",
    "### Merkmale\n",
    "\n",
    "- Niedriger Fehler auf dem Training Set\n",
    "- Niedriger Fehler auf dem Test Set\n",
    "- Kleine Lücke zwischen beiden\n",
    "\n",
    "### Numerisches Beispiel\n",
    "\n",
    "Modell 3: Polynom 2. Grades $h(x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2$\n",
    "\n",
    "Ergebnis:\n",
    "- Training Error: 2.1\n",
    "- Test Error: 2.8\n",
    "- Lücke: nur 0.7\n",
    "\n",
    "Perfekt! Erfasst das echte Muster (quadratisch) ohne das Rauschen auswendig zu lernen.\n",
    "\n",
    "## 7. Bias-Variance Trade-off\n",
    "\n",
    "### Die Gesamtfehler-Gleichung\n",
    "\n",
    "$$\\text{Gesamtfehler} = \\text{Bias}^2 + \\text{Variance} + \\text{Irreduzibles Rauschen}$$\n",
    "\n",
    "Wobei:\n",
    "- Bias²: Fehler durch zu einfaches Modell\n",
    "- Variance: Fehler durch zu empfindliches Modell\n",
    "- Irreduzibles Rauschen: inhärenter Fehler in den Daten (unvermeidbar)\n",
    "\n",
    "### Der Trade-off\n",
    "\n",
    "![Bias-Variance Trade-off](../Assets/bias_variance_tradeoff/3.png)\n",
    "\n",
    "### Umgekehrte Beziehung\n",
    "\n",
    "Komplexität erhöhen:\n",
    "- Bias nimmt ab (erfasst komplexe Muster)\n",
    "- Variance nimmt zu (empfindlich gegenüber Rauschen)\n",
    "  \n",
    "Komplexität verringern:\n",
    "- Bias nimmt zu (erfasst keine Muster)\n",
    "- Variance nimmt ab (stabiler)\n",
    "\n",
    "## 8. Wie diagnostiziert man das Problem?\n",
    "\n",
    "### Fehler vergleichen\n",
    "\n",
    "| Situation | Training Error | Test Error | Lücke | Diagnose |\n",
    "|----------|---------------|------------|-----|-------------|\n",
    "| A        | 45%           | 47%        | 2%  | Underfitting (hoher Bias) |\n",
    "| B        | 2%            | 3%         | 1%  | Just Right |\n",
    "| C        | 1%            | 25%        | 24% | Overfitting (hohe Variance) |\n",
    "\n",
    "## 9. Wie behebt man Underfitting (hoher Bias)?\n",
    "\n",
    "### Lösungen\n",
    "\n",
    "### 1. Modellkomplexität erhöhen\n",
    "\n",
    "Vorher:\n",
    "```python\n",
    "# Modell zu einfach\n",
    "h(x) = θ₀ + θ₁x  # Gerade Linie\n",
    "```\n",
    "\n",
    "Nachher:\n",
    "```python\n",
    "# Komplexeres Modell\n",
    "h(x) = θ₀ + θ₁x + θ₂x²  # Parabel\n",
    "```\n",
    "\n",
    "### 2. Mehr Features hinzufügen\n",
    "\n",
    "Vorher:\n",
    "```python\n",
    "# Nur 1 Feature\n",
    "X = [size]\n",
    "```\n",
    "\n",
    "Nachher:\n",
    "```python\n",
    "# Mehrere Features\n",
    "X = [size, bedrooms, age, location]\n",
    "```\n",
    "\n",
    "### 3. Feature Engineering\n",
    "\n",
    "Abgeleitete Features erstellen:\n",
    "```python\n",
    "# Original Features\n",
    "x₁ = size\n",
    "\n",
    "# Abgeleitete Features\n",
    "x₂ = size²\n",
    "x₃ = size³\n",
    "x₄ = sqrt(size)\n",
    "```\n",
    "\n",
    "### 4. Regularisierung entfernen\n",
    "\n",
    "Wenn Sie Regularisierung (λ) verwenden, verringern oder entfernen Sie sie:\n",
    "```python\n",
    "# Vorher: λ zu hoch\n",
    "λ = 10  # Erzwingt einfaches Modell\n",
    "\n",
    "# Nachher: λ kleiner oder null\n",
    "λ = 0  # Erlaubt flexibleres Modell\n",
    "```\n",
    "\n",
    "### 5. Länger trainieren\n",
    "\n",
    "Für neuronale Netze, Epochen erhöhen:\n",
    "```python\n",
    "# Vorher\n",
    "epochs = 10  # Früh gestoppt\n",
    "\n",
    "# Nachher\n",
    "epochs = 100  # Länger trainiert\n",
    "```\n",
    "\n",
    "### Vorsicht!\n",
    "\n",
    "Beim Beheben von Underfitting können Sie Overfitting verursachen. Überwachen Sie immer den Test Error!\n",
    "\n",
    "## 10. Wie behebt man Overfitting (hohe Variance)?\n",
    "\n",
    "### Lösungen\n",
    "\n",
    "### 1. Mehr Daten sammeln\n",
    "\n",
    "Die beste Lösung! Mehr Daten helfen dem Modell, besser zu generalisieren.\n",
    "\n",
    "Vorher:\n",
    "```python\n",
    "m = 100  # Wenige Beispiele\n",
    "```\n",
    "\n",
    "Nachher:\n",
    "```python\n",
    "m = 10000  # Viele Beispiele\n",
    "```\n",
    "\n",
    "Warum funktioniert es? Mit mehr Daten kann das Modell nicht alles \"auswendig lernen\" und wird gezwungen, echte Muster zu lernen.\n",
    "\n",
    "### 2. Modellkomplexität reduzieren\n",
    "\n",
    "Vorher:\n",
    "```python\n",
    "# Polynom 10. Grades\n",
    "h(x) = θ₀ + θ₁x + θ₂x² + ... + θ₁₀x¹⁰\n",
    "```\n",
    "\n",
    "Nachher:\n",
    "```python\n",
    "# Polynom 2. Grades\n",
    "h(x) = θ₀ + θ₁x + θ₂x²\n",
    "```\n",
    "\n",
    "### 3. Regularisierung (L1 oder L2)\n",
    "\n",
    "Strafe für große Gewichte hinzufügen:\n",
    "\n",
    "L2 Regularisierung (Ridge):\n",
    "$$J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} (h(x^{(i)}) - y^{(i)})^2 + \\lambda \\sum_{j=1}^{n} \\theta_j^2$$\n",
    "\n",
    "```python\n",
    "# λ kontrolliert, wie viel wir bestrafen\n",
    "λ = 0.1   # Moderate Regularisierung\n",
    "λ = 1.0   # Starke Regularisierung\n",
    "λ = 10.0  # Sehr starke Regularisierung\n",
    "```\n",
    "\n",
    "L1 Regularisierung (Lasso):\n",
    "$$J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} (h(x^{(i)}) - y^{(i)})^2 + \\lambda \\sum_{j=1}^{n} |\\theta_j|$$\n",
    "\n",
    "Effekt: Zwingt die Gewichte $\\theta$ klein zu sein, macht das Modell einfacher.\n",
    "\n",
    "### 4. Feature Selection (Features entfernen)\n",
    "\n",
    "Vorher:\n",
    "```python\n",
    "# Viele Features (20)\n",
    "X = [size, bedrooms, age, location, ..., feature_20]\n",
    "```\n",
    "\n",
    "Nachher:\n",
    "```python\n",
    "# Nur wichtige Features (5)\n",
    "X = [size, bedrooms, location, age, bathrooms]\n",
    "```\n",
    "\n",
    "### 5. Cross-Validation\n",
    "\n",
    "Daten in k-Folds zur Validierung aufteilen:\n",
    "\n",
    "![k-folds](../Assets/bias_variance_tradeoff/4.png)\n",
    "\n",
    "## 11. Zusammenfassung - Entscheidungstabelle\n",
    "\n",
    "| Problem | Symptome | Lösungen |\n",
    "|----------|----------|----------|\n",
    "| Underfitting | Hoher Training Error<br>Hoher Test Error<br>Kleine Lücke | 1. Modellkomplexität erhöhen<br>2. Mehr Features hinzufügen<br>3. Feature Engineering<br>4. Regularisierung verringern (λ)<br>5. Länger trainieren |\n",
    "| Overfitting | Niedriger Training Error<br>Hoher Test Error<br>Große Lücke | 1. Mehr Daten sammeln<br>2. Modellkomplexität reduzieren<br>3. Regularisierung hinzufügen (L1/L2)<br>4. Features entfernen<br>5. Cross-Validation |\n",
    "| Just Right | Niedriger Training Error<br>Niedriger Test Error<br>Kleine Lücke | Weiter so! |\n",
    "\n",
    "## 12. Vollständiges praktisches Beispiel\n",
    "\n",
    "### Datensatz: Hauspreise vorhersagen\n",
    "\n",
    "```python\n",
    "# Daten\n",
    "X_train: 80 Häuser\n",
    "y_train: Preise\n",
    "\n",
    "X_test: 20 Häuser\n",
    "y_test: Preise\n",
    "```\n",
    "\n",
    "### Versuch 1: Einfache Linie\n",
    "\n",
    "```python\n",
    "model = LinearRegression()  # h(x) = θ₀ + θ₁x\n",
    "```\n",
    "\n",
    "Ergebnis:\n",
    "- Training Error: 42%\n",
    "- Test Error: 45%\n",
    "- Diagnose: UNDERFITTING\n",
    "\n",
    "Aktion: Komplexität erhöhen\n",
    "\n",
    "### Versuch 2: Polynom 2. Grades\n",
    "\n",
    "```python\n",
    "model = PolynomialRegression(degree=2)  # h(x) = θ₀ + θ₁x + θ₂x²\n",
    "```\n",
    "\n",
    "Ergebnis:\n",
    "- Training Error: 5%\n",
    "- Test Error: 8%\n",
    "- Diagnose: JUST RIGHT\n",
    "\n",
    "Aktion: Erfolg! Ausgewogenes Modell.\n",
    "\n",
    "### Versuch 3: Polynom 10. Grades\n",
    "\n",
    "```python\n",
    "model = PolynomialRegression(degree=10)\n",
    "```\n",
    "\n",
    "Ergebnis:\n",
    "- Training Error: 0.5%\n",
    "- Test Error: 45%\n",
    "- Diagnose: OVERFITTING\n",
    "\n",
    "Aktion: Regularisierung anwenden\n",
    "\n",
    "### Versuch 4: Polynom 10. Grades + Regularisierung\n",
    "\n",
    "```python\n",
    "model = Ridge(degree=10, alpha=1.0)  # α = λ (Regularisierung)\n",
    "```\n",
    "\n",
    "Ergebnis:\n",
    "- Training Error: 4%\n",
    "- Test Error: 6%\n",
    "- Diagnose: JUST RIGHT\n",
    "\n",
    "Aktion: Erfolg! Regularisierung hat es gelöst.\n",
    "\n",
    "## 13. Abschließende Tipps\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. Immer Train/Test trennen (80/20 oder 70/30)\n",
    "2. Cross-Validation verwenden, um Hyperparameter zu wählen\n",
    "3. Einfach beginnen, Komplexität schrittweise hinzufügen\n",
    "4. Beide Fehler überwachen (Training und Test)\n",
    "5. Lernkurven plotten zur Visualisierung\n",
    "\n",
    "### Häufige Fehler\n",
    "\n",
    "1. Test Set nicht trennen (auf denselben Daten trainieren und testen)\n",
    "2. Test Set zum Modell-Tuning verwenden (Data Leakage)\n",
    "3. Übermäßige Komplexität von Anfang an\n",
    "4. Training Error ignorieren (nur auf Test fokussieren)\n",
    "5. Regularisierung nicht verwenden, wenn angebracht\n",
    "\n",
    "---\n",
    "\n",
    "Denken Sie daran:\n",
    "_\"Das beste Modell ist nicht das, das sich am besten an die Trainingsdaten anpasst, sondern das, das am besten auf neue Daten generalisiert.\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e21c1d2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
