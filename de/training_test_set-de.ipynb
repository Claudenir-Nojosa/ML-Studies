{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8aed3bb",
   "metadata": {},
   "source": [
    "# Train, Validation und Test Split\n",
    "\n",
    "## Einführung\n",
    "\n",
    "Nach der Implementierung eines Machine-Learning-Modells stellt sich eine grundlegende Frage: **Woher wissen wir, ob unser Modell wirklich gut funktioniert?** Ein Modell zu trainieren und es mit denselben Daten zu testen, reicht nicht aus, da dies nicht garantiert, dass es bei neuen Daten, die es noch nie gesehen hat, gut funktionieren wird.\n",
    "\n",
    "Die Aufteilung der Daten in **Trainings-**, **Validierungs-** und **Test-Sets** ist eine wesentliche Praxis zur ordnungsgemäßen Bewertung der Leistung von Machine-Learning-Modellen.\n",
    "\n",
    "---\n",
    "\n",
    "## Das Problem: Overfitting vs Underfitting\n",
    "\n",
    "### Overfitting (Überanpassung)\n",
    "\n",
    "**Overfitting** tritt auf, wenn das Modell die Trainingsdaten \"auswendig lernt\" und nicht nur die echten Muster erfasst, sondern auch das Rauschen und spezifische Besonderheiten dieser Daten.\n",
    "\n",
    "**Merkmale:**\n",
    "- ✅ **Ausgezeichnete** Leistung bei Trainingsdaten\n",
    "- ❌ **Schlechte** Leistung bei neuen Daten\n",
    "- Das Modell ist zu spezifisch und generalisiert nicht\n",
    "\n",
    "**Analogie:** Es ist wie ein Schüler, der die Antworten alter Prüfungen auswendig lernt, aber die Konzepte nicht versteht. Er schneidet bei alten Prüfungen gut ab, scheitert aber bei neuen Fragen.\n",
    "\n",
    "### Underfitting (Unteranpassung)\n",
    "\n",
    "**Underfitting** tritt auf, wenn das Modell zu einfach ist und die in den Daten vorhandenen Muster nicht erfassen kann.\n",
    "\n",
    "**Merkmale:**\n",
    "- ❌ **Schlechte** Leistung bei Trainingsdaten\n",
    "- ❌ **Schlechte** Leistung bei neuen Daten\n",
    "- Das Modell ist zu einfach\n",
    "\n",
    "**Analogie:** Es ist wie ein Schüler, der nicht genug gelernt hat und nicht einmal grundlegende Fragen beantworten kann.\n",
    "\n",
    "### Das ideale Gleichgewicht\n",
    "\n",
    "Das Ziel ist es, den **optimalen Punkt** zu finden, an dem das Modell:\n",
    "- Die echten Muster in den Daten lernt\n",
    "- Gut auf neue Daten generalisiert\n",
    "- Keine spezifischen Besonderheiten auswendig lernt\n",
    "\n",
    "---\n",
    "\n",
    "## Train/Test Split (Grundlegende Aufteilung)\n",
    "\n",
    "### Konzept\n",
    "\n",
    "Die einfachste Aufteilung teilt die Daten in **zwei Sets**:\n",
    "\n",
    "1. **Training Set (Trainingsmenge)**: ~70-80% der Daten\n",
    "   - Wird zum Trainieren des Modells verwendet\n",
    "   - Das Modell lernt hier die Muster\n",
    "\n",
    "2. **Test Set (Testmenge)**: ~20-30% der Daten\n",
    "   - Wird **nur** zur Bewertung des endgültigen Modells verwendet\n",
    "   - Simuliert \"reale\" Daten, die das Modell nie gesehen hat\n",
    "\n",
    "### Warum dies tun?\n",
    "\n",
    "**Ohne Aufteilung:**\n",
    "```\n",
    "Training auf Dataset → Test auf demselben Dataset → R² = 0.99 ✅\n",
    "```\n",
    "Sieht großartig aus, ist aber **irreführend**! Das Modell könnte nur auswendig lernen.\n",
    "\n",
    "**Mit Aufteilung:**\n",
    "```\n",
    "Training auf Trainingsset → Test auf Testset → R² = 0.95 ✅\n",
    "```\n",
    "Jetzt haben wir ein **echtes** Maß dafür, wie das Modell generalisiert.\n",
    "\n",
    "### Typische Proportionen\n",
    "\n",
    "| Datensatzgröße | Train | Test |\n",
    "|-------------------|-------|------|\n",
    "| Klein (< 1000) | 70% | 30% |\n",
    "| Mittel (1k-100k) | 80% | 20% |\n",
    "| Groß (> 100k) | 90% | 10% |\n",
    "\n",
    "**Allgemeine Regel:** Je mehr Daten Sie haben, desto kleiner ist der Prozentsatz, der zum Testen benötigt wird.\n",
    "\n",
    "---\n",
    "\n",
    "## Train/Validation/Test Split (Vollständige Aufteilung)\n",
    "\n",
    "### Konzept\n",
    "\n",
    "Für robustere Projekte teilen wir die Daten in **drei Sets**:\n",
    "\n",
    "1. **Training Set**: ~60-70% der Daten\n",
    "   - Wird zum Trainieren des Modells verwendet\n",
    "   - Passt Parameter an (w, b)\n",
    "\n",
    "2. **Validation Set (Validierungsmenge)**: ~15-20% der Daten\n",
    "   - Wird zum **Tuning von Hyperparametern** verwendet\n",
    "   - Vergleich verschiedener Modelle\n",
    "   - Erkennung von Overfitting während des Trainings\n",
    "   - Wird **nicht** zum Training verwendet\n",
    "\n",
    "3. **Test Set**: ~15-20% der Daten\n",
    "   - Wird **nur einmal** am Ende verwendet\n",
    "   - Endgültige und unvoreingenommene Bewertung\n",
    "   - Simuliert die Produktionsleistung\n",
    "\n",
    "### Warum drei Sets?\n",
    "\n",
    "**Problem mit nur Train/Test:**\n",
    "- Wenn wir das Testset zum Anpassen von Hyperparametern verwenden, \"leckt\" es Informationen (Data Leakage)\n",
    "- Das Testset hört auf, unvoreingenommen zu sein\n",
    "- Wir können auf dem Testset überanpassen!\n",
    "\n",
    "**Lösung mit Train/Validation/Test:**\n",
    "- **Validation** wird für Experimente und Anpassungen verwendet\n",
    "- **Test** bleibt bis zum Ende \"unberührt\"\n",
    "- Wir haben eine wirklich unvoreingenommene Bewertung\n",
    "\n",
    "---\n",
    "\n",
    "## Zufällige vs Stratifizierte Aufteilung\n",
    "\n",
    "### Zufällige Aufteilung\n",
    "\n",
    "Wählt zufällig Beispiele für jedes Set aus.\n",
    "\n",
    "```python\n",
    "np.random.shuffle(data)\n",
    "train = data[:60%]\n",
    "val = data[60%:80%]\n",
    "test = data[80%:]\n",
    "```\n",
    "\n",
    "**Wann zu verwenden:**\n",
    "- Ausgewogene Daten\n",
    "- Regression (kontinuierliche Werte)\n",
    "- Große Datensätze\n",
    "\n",
    "### Stratifizierte Aufteilung\n",
    "\n",
    "Behält die **gleiche Proportion der Klassen** in allen Sets bei.\n",
    "\n",
    "**Wann zu verwenden:**\n",
    "- Klassifikation mit unausgewogenen Klassen\n",
    "- Bsp.: 95% Klasse A, 5% Klasse B\n",
    "- Stellt sicher, dass Train, Val und Test ~95%/5% haben\n",
    "\n",
    "---\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "### ✅ Was zu tun ist\n",
    "\n",
    "1. **Teilen VOR jeder Verarbeitung**\n",
    "   - Normalisieren Sie nach der Aufteilung\n",
    "   - Vermeidet \"Data Leakage\"\n",
    "\n",
    "2. **Niemals mit Validierungs-/Testdaten trainieren**\n",
    "   - Validierung dient nur der Bewertung\n",
    "   - Test dient nur der Endbewertung\n",
    "\n",
    "3. **Testset \"heilig\" halten**\n",
    "   - Nur EINMAL am Ende verwenden\n",
    "   - Passen Sie nichts danach an\n",
    "\n",
    "4. **Daten mischen (Shuffle)**\n",
    "   - Vermeidet Bias, wenn Daten geordnet sind\n",
    "\n",
    "### ❌ Was NICHT zu tun ist\n",
    "\n",
    "1. Vor dem Teilen normalisieren (verursacht Data Leakage)\n",
    "2. Testset zum Anpassen von Hyperparametern verwenden\n",
    "3. Mit Validierungs-/Testset trainieren\n",
    "4. Mehrmals auf Testset bewerten\n",
    "5. Zeitliche Daten zufällig aufteilen (zeitliche Aufteilung verwenden)\n",
    "\n",
    "---\n",
    "\n",
    "## Zeitliche Daten (Zeitreihen)\n",
    "\n",
    "Bei Daten mit zeitlicher Komponente (Aktienkurse, Verkäufe im Zeitverlauf) **NICHT mischen**!\n",
    "\n",
    "**Beispiel:**\n",
    "- Train: Januar - August (8 Monate)\n",
    "- Validation: September - Oktober (2 Monate)\n",
    "- Test: November - Dezember (2 Monate)\n",
    "\n",
    "**Warum?**\n",
    "- In der Produktion sagen Sie immer die Zukunft basierend auf der Vergangenheit voraus\n",
    "- Mischen erzeugt \"zeitliches Leakage\" (Modell sieht die Zukunft)\n",
    "\n",
    "---\n",
    "\n",
    "## Zusammenfassung\n",
    "\n",
    "| Datentyp | Train Set | Validation Set | Test Set |\n",
    "|---------|-----------|----------------|----------|\n",
    "| **Verwendung** | Modell trainieren | Hyperparameter anpassen | Endbewertung |\n",
    "| **Häufigkeit** | Mehrmals | Mehrmals | **Einmal** |\n",
    "| **Größe** | 60-80% | 10-20% | 10-20% |\n",
    "| **Kann trainieren?** | ✅ Ja | ❌ Nein | ❌ Nein |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822bef58",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6718d2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# IMPORTE\n",
    "# ============================================================\n",
    "\n",
    "# Bibliothek für numerische Berechnungen\n",
    "import numpy as np\n",
    "\n",
    "# Bibliothek für Visualisierung\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Funktion zur Aufteilung der Daten in Trainings- und Testdaten\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Lineares Regressionsmodell\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# R²-Metrik (Bestimmtheitsmaß)\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6e8fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DATENERZEUGUNG (SYNTHETISCHER DATENSATZ)\n",
    "# ============================================================\n",
    "\n",
    "# Fixiert den Zufalls-Seed für Reproduzierbarkeit\n",
    "np.random.seed(42)\n",
    "\n",
    "# Unabhängige Variable X (50 Punkte zwischen 0 und 10)\n",
    "X = np.random.rand(50, 1) * 10\n",
    "\n",
    "# Abhängige Variable y\n",
    "# Lineare Beziehung: y = 2.5x + 5 + Rauschen\n",
    "y = 2.5 * X.ravel() + 5 + np.random.randn(50) * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa92f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SZENARIO 1 — OHNE TRAIN/TEST-SPLIT (FALSCH)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n❌ SZENARIO 1: OHNE TRAIN/TEST-SPLIT\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Modell erstellen\n",
    "model_no_split = LinearRegression()\n",
    "\n",
    "# Modell mit ALLEN Daten trainieren\n",
    "model_no_split.fit(X, y)\n",
    "\n",
    "# Vorhersagen mit denselben Daten wie im Training\n",
    "y_pred_no_split = model_no_split.predict(X)\n",
    "\n",
    "# R² berechnen mit Training = Test (Problem!)\n",
    "r2_no_split = r2_score(y, y_pred_no_split)\n",
    "\n",
    "print(f\"R² = {r2_no_split:.4f}\")\n",
    "print(\"⚠️  Irreführende Bewertung: Das Modell wurde mit den gleichen Daten getestet, mit denen es trainiert wurde!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd27f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SZENARIO 2 — MIT TRAIN/TEST-SPLIT (KORREKT)\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"✅ SZENARIO 2: MIT TRAIN/TEST-SPLIT\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Aufteilung der Daten:\n",
    "# 70% Training | 30% Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training: {len(X_train)} Beispiele | Test: {len(X_test)} Beispiele\\n\")\n",
    "\n",
    "# Modell erstellen\n",
    "model_good = LinearRegression()\n",
    "\n",
    "# Training NUR mit Trainingsdaten\n",
    "model_good.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen auf Trainingsdaten\n",
    "y_train_pred = model_good.predict(X_train)\n",
    "\n",
    "# Vorhersagen auf NIE zuvor gesehenen Daten (Test)\n",
    "y_test_pred = model_good.predict(X_test)\n",
    "\n",
    "# Korrekte Bewertung\n",
    "r2_train_good = r2_score(y_train, y_train_pred)\n",
    "r2_test_good = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"R² Training: {r2_train_good:.4f}\")\n",
    "print(f\"R² Test:     {r2_test_good:.4f}\")\n",
    "print(f\"Differenz:   {abs(r2_train_good - r2_test_good):.4f}\")\n",
    "print(\"✨ Das Modell generalisiert gut!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91aa0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VISUALISIERUNG — TRAIN vs TEST (SAUBERE VERSION)\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Kontinuierliche Linie für die Regression\n",
    "X_line = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
    "\n",
    "# Blaue Farbpalette\n",
    "blue_light = \"#7EC8E3\"\n",
    "blue_dark = \"#1F4E79\"\n",
    "blue_mid = \"#3A7CA5\"\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# DIAGRAMM 1 — OHNE SPLIT\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "axes[0].scatter(\n",
    "    X, y,\n",
    "    s=90,\n",
    "    color=blue_light,\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "axes[0].plot(\n",
    "    X_line,\n",
    "    model_no_split.predict(X_line),\n",
    "    color=blue_dark,\n",
    "    linewidth=3\n",
    ")\n",
    "\n",
    "axes[0].set_title(\n",
    "    f\"Ohne Train/Test-Split\\nR² = {r2_no_split:.3f}\",\n",
    "    fontsize=13,\n",
    "    fontweight=\"bold\",\n",
    "    color=blue_dark\n",
    ")\n",
    "\n",
    "axes[0].set_xlabel(\"X\")\n",
    "axes[0].set_ylabel(\"y\")\n",
    "axes[0].grid(True, alpha=0.25)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# DIAGRAMM 2 — MIT SPLIT\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Trainingsdaten\n",
    "axes[1].scatter(\n",
    "    X_train, y_train,\n",
    "    s=90,\n",
    "    color=blue_mid,\n",
    "    alpha=0.75,\n",
    "    label=\"Training\"\n",
    ")\n",
    "\n",
    "# Testdaten\n",
    "axes[1].scatter(\n",
    "    X_test, y_test,\n",
    "    s=90,\n",
    "    color=blue_light,\n",
    "    edgecolor=blue_dark,\n",
    "    linewidth=1.5,\n",
    "    label=\"Test\"\n",
    ")\n",
    "\n",
    "# Modell, trainiert mit Trainingsdaten\n",
    "axes[1].plot(\n",
    "    X_line,\n",
    "    model_good.predict(X_line),\n",
    "    color=blue_dark,\n",
    "    linewidth=3\n",
    ")\n",
    "\n",
    "axes[1].set_title(\n",
    "    f\"Mit Train/Test-Split\\nTrain={r2_train_good:.2f} | Test={r2_test_good:.2f}\",\n",
    "    fontsize=13,\n",
    "    fontweight=\"bold\",\n",
    "    color=blue_dark\n",
    ")\n",
    "\n",
    "axes[1].set_xlabel(\"X\")\n",
    "axes[1].set_ylabel(\"y\")\n",
    "axes[1].legend(frameon=False)\n",
    "axes[1].grid(True, alpha=0.25)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e7e2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
