{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8aed3bb",
   "metadata": {},
   "source": [
    "# Train, Validation and Test Split\n",
    "\n",
    "## Introduction\n",
    "\n",
    "After implementing a Machine Learning model, a fundamental question arises: **how do we know if our model truly works well?** Training a model and testing it on the same data is not sufficient, as this does not guarantee it will perform well on new data it has never seen before.\n",
    "\n",
    "Splitting data into **training**, **validation**, and **test** sets is an essential practice for properly evaluating the performance of machine learning models.\n",
    "\n",
    "---\n",
    "\n",
    "## The Problem: Overfitting vs Underfitting\n",
    "\n",
    "### Overfitting\n",
    "\n",
    "**Overfitting** occurs when the model \"memorizes\" the training data, capturing not only the real patterns but also the noise and specific peculiarities of that data.\n",
    "\n",
    "**Characteristics:**\n",
    "- ✅ **Excellent** performance on training data\n",
    "- ❌ **Poor** performance on new data\n",
    "- The model is too specific and does not generalize\n",
    "\n",
    "**Analogy:** It's like a student who memorizes answers from old exams but doesn't understand the concepts. They do well on old exams but fail on new questions.\n",
    "\n",
    "### Underfitting\n",
    "\n",
    "**Underfitting** occurs when the model is too simple and cannot capture the patterns present in the data.\n",
    "\n",
    "**Characteristics:**\n",
    "- ❌ **Poor** performance on training data\n",
    "- ❌ **Poor** performance on new data\n",
    "- The model is too simple\n",
    "\n",
    "**Analogy:** It's like a student who didn't study enough and can't answer even basic questions.\n",
    "\n",
    "### The Ideal Balance\n",
    "\n",
    "The goal is to find the **sweet spot** where the model:\n",
    "- Learns the real patterns in the data\n",
    "- Generalizes well to new data\n",
    "- Does not memorize specific peculiarities\n",
    "\n",
    "---\n",
    "\n",
    "## Train/Test Split (Basic Division)\n",
    "\n",
    "### Concept\n",
    "\n",
    "The simplest division separates the data into **two sets**:\n",
    "\n",
    "1. **Training Set**: ~70-80% of the data\n",
    "   - Used to train the model\n",
    "   - The model learns patterns here\n",
    "\n",
    "2. **Test Set**: ~20-30% of the data\n",
    "   - Used **only** to evaluate the final model\n",
    "   - Simulates \"real-world\" data the model has never seen\n",
    "\n",
    "### Why Do This?\n",
    "\n",
    "**Without split:**\n",
    "```\n",
    "Train on dataset → Test on same dataset → R² = 0.99 ✅\n",
    "```\n",
    "Looks great, but it's **misleading**! The model might just be memorizing.\n",
    "\n",
    "**With split:**\n",
    "```\n",
    "Train on training set → Test on test set → R² = 0.95 ✅\n",
    "```\n",
    "Now we have a **real** measure of how the model generalizes.\n",
    "\n",
    "### Typical Proportions\n",
    "\n",
    "| Dataset Size | Train | Test |\n",
    "|-------------------|-------|------|\n",
    "| Small (< 1000) | 70% | 30% |\n",
    "| Medium (1k-100k) | 80% | 20% |\n",
    "| Large (> 100k) | 90% | 10% |\n",
    "\n",
    "**General rule:** The more data you have, the smaller the percentage needed for testing.\n",
    "\n",
    "---\n",
    "\n",
    "## Train/Validation/Test Split (Complete Division)\n",
    "\n",
    "### Concept\n",
    "\n",
    "For more robust projects, we divide the data into **three sets**:\n",
    "\n",
    "1. **Training Set**: ~60-70% of the data\n",
    "   - Used to train the model\n",
    "   - Adjusts parameters (w, b)\n",
    "\n",
    "2. **Validation Set**: ~15-20% of the data\n",
    "   - Used to **tune hyperparameters**\n",
    "   - Compare different models\n",
    "   - Detect overfitting during training\n",
    "   - **Not** used for training\n",
    "\n",
    "3. **Test Set**: ~15-20% of the data\n",
    "   - Used **only once** at the end\n",
    "   - Final and unbiased evaluation\n",
    "   - Simulates production performance\n",
    "\n",
    "### Why Three Sets?\n",
    "\n",
    "**Problem with only Train/Test:**\n",
    "- If we use the test set to adjust hyperparameters, it \"leaks\" information (data leakage)\n",
    "- The test set ceases to be unbiased\n",
    "- We can overfit on the test set!\n",
    "\n",
    "**Solution with Train/Validation/Test:**\n",
    "- **Validation** is used for experimentation and adjustments\n",
    "- **Test** remains \"untouched\" until the end\n",
    "- We have a truly unbiased evaluation\n",
    "\n",
    "---\n",
    "\n",
    "## Random vs Stratified Split\n",
    "\n",
    "### Random Split\n",
    "\n",
    "Randomly selects examples for each set.\n",
    "\n",
    "```python\n",
    "np.random.shuffle(data)\n",
    "train = data[:60%]\n",
    "val = data[60%:80%]\n",
    "test = data[80%:]\n",
    "```\n",
    "\n",
    "**When to use:**\n",
    "- Balanced data\n",
    "- Regression (continuous values)\n",
    "- Large datasets\n",
    "\n",
    "### Stratified Split\n",
    "\n",
    "Maintains the **same proportion of classes** in all sets.\n",
    "\n",
    "**When to use:**\n",
    "- Classification with imbalanced classes\n",
    "- Ex: 95% class A, 5% class B\n",
    "- Ensures train, val, and test have ~95%/5%\n",
    "\n",
    "---\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "### ✅ What to Do\n",
    "\n",
    "1. **Split BEFORE any processing**\n",
    "   - Normalize after splitting\n",
    "   - Avoids \"data leakage\"\n",
    "\n",
    "2. **Never train with validation/test data**\n",
    "   - Validation is only for evaluation\n",
    "   - Test is only for final evaluation\n",
    "\n",
    "3. **Keep test set \"sacred\"**\n",
    "   - Use only ONCE at the end\n",
    "   - Don't adjust anything based on it\n",
    "\n",
    "4. **Shuffle the data**\n",
    "   - Avoids bias if data is ordered\n",
    "\n",
    "### ❌ What NOT to Do\n",
    "\n",
    "1. Normalize before splitting (causes data leakage)\n",
    "2. Use test set to adjust hyperparameters\n",
    "3. Train with validation/test set\n",
    "4. Evaluate multiple times on test set\n",
    "5. Randomly split temporal data (use temporal split)\n",
    "\n",
    "---\n",
    "\n",
    "## Temporal Data (Time Series)\n",
    "\n",
    "For data with a temporal component (stock prices, sales over time), **DO NOT shuffle**!\n",
    "\n",
    "**Example:**\n",
    "- Train: January - August (8 months)\n",
    "- Validation: September - October (2 months)\n",
    "- Test: November - December (2 months)\n",
    "\n",
    "**Why?**\n",
    "- In production, you always predict the future based on the past\n",
    "- Shuffling creates \"temporal leakage\" (model sees the future)\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "| Data Type | Train Set | Validation Set | Test Set |\n",
    "|---------|-----------|----------------|----------|\n",
    "| **Usage** | Train model | Adjust hyperparameters | Final evaluation |\n",
    "| **Frequency** | Multiple times | Multiple times | **Once** |\n",
    "| **Size** | 60-80% | 10-20% | 10-20% |\n",
    "| **Can train?** | ✅ Yes | ❌ No | ❌ No |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822bef58",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6718d2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# IMPORTS\n",
    "# ============================================================\n",
    "\n",
    "# Library for numerical computation\n",
    "import numpy as np\n",
    "\n",
    "# Library for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to split data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# R² metric (coefficient of determination)\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6e8fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DATA GENERATION (SYNTHETIC DATASET)\n",
    "# ============================================================\n",
    "\n",
    "# Fix the random seed to ensure reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Independent variable X (50 points between 0 and 10)\n",
    "X = np.random.rand(50, 1) * 10\n",
    "\n",
    "# Dependent variable y\n",
    "# Linear relationship: y = 2.5x + 5 + noise\n",
    "y = 2.5 * X.ravel() + 5 + np.random.randn(50) * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa92f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SCENARIO 1 — WITHOUT TRAIN/TEST SPLIT (WRONG)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n❌ SCENARIO 1: WITHOUT TRAIN/TEST SPLIT\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Create the model\n",
    "model_no_split = LinearRegression()\n",
    "\n",
    "# Train the model using ALL data\n",
    "model_no_split.fit(X, y)\n",
    "\n",
    "# Make predictions on the same data used for training\n",
    "y_pred_no_split = model_no_split.predict(X)\n",
    "\n",
    "# Compute R² using training = test (problem!)\n",
    "r2_no_split = r2_score(y, y_pred_no_split)\n",
    "\n",
    "print(f\"R² = {r2_no_split:.4f}\")\n",
    "print(\"⚠️  Misleading evaluation: the model was tested on the same data it was trained on!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd27f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SCENARIO 2 — WITH TRAIN/TEST SPLIT (CORRECT)\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"✅ SCENARIO 2: WITH TRAIN/TEST SPLIT\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Split the data:\n",
    "# 70% training | 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training: {len(X_train)} samples | Test: {len(X_test)} samples\\n\")\n",
    "\n",
    "# Create the model\n",
    "model_good = LinearRegression()\n",
    "\n",
    "# Train ONLY using training data\n",
    "model_good.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on training data\n",
    "y_train_pred = model_good.predict(X_train)\n",
    "\n",
    "# Predictions on data NEVER seen before (test)\n",
    "y_test_pred = model_good.predict(X_test)\n",
    "\n",
    "# Proper evaluation\n",
    "r2_train_good = r2_score(y_train, y_train_pred)\n",
    "r2_test_good = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"R² Training: {r2_train_good:.4f}\")\n",
    "print(f\"R² Test:     {r2_test_good:.4f}\")\n",
    "print(f\"Difference:  {abs(r2_train_good - r2_test_good):.4f}\")\n",
    "print(\"✨ The model generalizes well!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91aa0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VISUALIZATION — TRAIN vs TEST (CLEAN VERSION)\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Continuous line for regression\n",
    "X_line = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
    "\n",
    "# Blue color palette\n",
    "blue_light = \"#7EC8E3\"\n",
    "blue_dark = \"#1F4E79\"\n",
    "blue_mid = \"#3A7CA5\"\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# PLOT 1 — WITHOUT SPLIT\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "axes[0].scatter(\n",
    "    X, y,\n",
    "    s=90,\n",
    "    color=blue_light,\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "axes[0].plot(\n",
    "    X_line,\n",
    "    model_no_split.predict(X_line),\n",
    "    color=blue_dark,\n",
    "    linewidth=3\n",
    ")\n",
    "\n",
    "axes[0].set_title(\n",
    "    f\"Without Train/Test Split\\nR² = {r2_no_split:.3f}\",\n",
    "    fontsize=13,\n",
    "    fontweight=\"bold\",\n",
    "    color=blue_dark\n",
    ")\n",
    "\n",
    "axes[0].set_xlabel(\"X\")\n",
    "axes[0].set_ylabel(\"y\")\n",
    "axes[0].grid(True, alpha=0.25)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# PLOT 2 — WITH SPLIT\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Training data\n",
    "axes[1].scatter(\n",
    "    X_train, y_train,\n",
    "    s=90,\n",
    "    color=blue_mid,\n",
    "    alpha=0.75,\n",
    "    label=\"Training\"\n",
    ")\n",
    "\n",
    "# Test data\n",
    "axes[1].scatter(\n",
    "    X_test, y_test,\n",
    "    s=90,\n",
    "    color=blue_light,\n",
    "    edgecolor=blue_dark,\n",
    "    linewidth=1.5,\n",
    "    label=\"Test\"\n",
    ")\n",
    "\n",
    "# Model trained on training data\n",
    "axes[1].plot(\n",
    "    X_line,\n",
    "    model_good.predict(X_line),\n",
    "    color=blue_dark,\n",
    "    linewidth=3\n",
    ")\n",
    "\n",
    "axes[1].set_title(\n",
    "    f\"With Train/Test Split\\nTrain={r2_train_good:.2f} | Test={r2_test_good:.2f}\",\n",
    "    fontsize=13,\n",
    "    fontweight=\"bold\",\n",
    "    color=blue_dark\n",
    ")\n",
    "\n",
    "axes[1].set_xlabel(\"X\")\n",
    "axes[1].set_ylabel(\"y\")\n",
    "axes[1].legend(frameon=False)\n",
    "axes[1].grid(True, alpha=0.25)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e7e2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
