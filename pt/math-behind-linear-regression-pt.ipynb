{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d926547c",
   "metadata": {},
   "source": [
    "# Regressão Linear\n",
    "\n",
    "## Conceito Fundamental\n",
    "\n",
    "A Regressão Linear é um algoritmo de aprendizado de máquina cujo objetivo principal é encontrar a melhor reta que atravessa os pontos de dados disponíveis. Este método busca estabelecer uma relação linear entre as variáveis de entrada e saída, permitindo realizar previsões precisas sobre novos dados.\n",
    "\n",
    "## Aprendizado Supervisionado\n",
    "\n",
    "![Capa](../Assets/linear_regression/input.png)\n",
    "\n",
    "A Regressão Linear é classificada como um algoritmo de **aprendizado supervisionado** (*supervised learning*). Esta caracterização se deve ao fato de que o algoritmo utiliza um conjunto de dados de treinamento contendo tanto as *features* de entrada quanto os *targets* de saída correspondentes. Durante o processo de treinamento, o modelo aprende a mapear as relações entre estas entradas e saídas conhecidas.\n",
    "\n",
    "## Modelo Matemático\n",
    "\n",
    "Uma vez que o modelo é treinado, ele se torna capaz de prever valores $\\hat{y}$ (*y-hat*) para novos inputs $x$. Esta previsão pode ser representada matematicamente pela seguinte função:\n",
    "\n",
    "![Capa](../Assets/linear_regression/w_e_b.png)\n",
    "\n",
    "$$f(x) = wx + b$$\n",
    "\n",
    "Onde:\n",
    "- $f(x)$ ou $\\hat{y}$ representa o valor previsto\n",
    "- $w$ é o coeficiente angular (*slope*) da reta\n",
    "- $b$ é o intercepto (*intercept*) da reta\n",
    "- $x$ é a *feature* de entrada\n",
    "\n",
    "## Parâmetros do Modelo\n",
    "\n",
    "Os valores escolhidos para os parâmetros $w$ e $b$ são fundamentais, pois determinam completamente o comportamento do modelo. Especificamente, estes parâmetros definem o valor da predição $\\hat{y}_i$ para cada exemplo $i$, baseado na *feature* de entrada $x_i$ correspondente. A otimização destes parâmetros durante o treinamento é o que permite ao modelo realizar previsões precisas.\n",
    "\n",
    "## Função de Custo\n",
    "\n",
    "Para encontrar os melhores valores para $w$ e $b$, reduzimos o que chamamos de **função de custo** (*cost function*). O objetivo é escolher valores de $w$ e $b$ de maneira que a predição $\\hat{y}_i$ seja o mais próxima possível do valor real $y_i$ para todos os exemplos do conjunto de treinamento.\n",
    "\n",
    "### Construção da Função de Custo\n",
    "\n",
    "A função de custo funciona comparando o valor real $y_i$ com o valor previsto $\\hat{y}_i$. A diferença entre esses valores é expressa como:\n",
    "\n",
    "$$\\hat{y}_i - y_i$$\n",
    "\n",
    "Esta diferença é denominada **erro** (*error*) da predição.\n",
    "\n",
    "Para obter uma métrica mais robusta, elevamos esse erro ao quadrado. Isso possui dois propósitos importantes: anular os valores negativos (garantindo que erros positivos e negativos não se cancelem) e penalizar mais intensamente erros maiores:\n",
    "\n",
    "$$(\\hat{y}_i - y_i)^2$$\n",
    "\n",
    "Como desejamos quantificar o erro sobre todo o conjunto de dados, somamos os erros quadráticos de todos os exemplos de treinamento:\n",
    "\n",
    "$$\\sum_{i=1}^{m} (\\hat{y}_i - y_i)^2$$\n",
    "\n",
    "onde $m$ representa o número total de exemplos de treinamento (*training examples*) ou pontos de dados (*datapoints*).\n",
    "\n",
    "Por fim, calculamos a média desses erros dividindo por $2m$. A escolha de $2m$ ao invés de apenas $m$ tem o intuito de simplificar a matemática no futuro, especialmente ao calcular a derivada parcial da função de custo.\n",
    "\n",
    "Como $\\hat{y}_i$ pode ser representado como $f(x_i)$, a **função de custo** completa é expressa como:\n",
    "\n",
    "$$J(w, b) = \\frac{1}{2m} \\sum_{i=1}^{m} (f(x_i) - y_i)^2$$\n",
    "\n",
    "Esta função, conhecida como **Erro Quadrático Médio** (*Mean Squared Error* - MSE), é a função de custo mais comumente utilizada em problemas de Regressão Linear.\n",
    "\n",
    "## Gradient Descent\n",
    "\n",
    "Para minimizar a função de custo, utilizamos um algoritmo chamado **Gradient Descent** (*Descida do Gradiente*). O processo é relativamente simples: começamos com valores iniciais para $w$ e $b$ (comumente $w = 0$ e $b = 0$).\n",
    "\n",
    "Em seguida, atualizamos repetidamente os parâmetros $w$ e $b$ em pequenos passos com o objetivo de reduzir o custo. Continuamos esse processo iterativo até alcançarmos o menor custo possível (mínimo local). Quando o algoritmo atinge esse ponto, dizemos que ele **convergiu**.\n",
    "\n",
    "![Gradient Descent](../Assets/linear_regression/gradient.png)\n",
    "\n",
    "O processo pode ser comparado a descer uma montanha: cada passo nos leva mais perto do fundo do vale. A direção em cada etapa é determinada pelo **gradiente**, que sempre aponta na direção da maior subida (*steepest ascent*).\n",
    "\n",
    "![Gradient Descent Steps](../Assets/linear_regression/steps.png)\n",
    "\n",
    "Para minimizar o custo, movemos na direção oposta ao gradiente, ou seja, damos passos descendo a montanha (*downhill*).\n",
    "\n",
    "### Fórmula do Gradient Descent\n",
    "\n",
    "A atualização dos parâmetros em cada iteração segue as seguintes equações:\n",
    "\n",
    "$w = w - \\alpha \\frac{\\partial J(w,b)}{\\partial w}$\n",
    "\n",
    "$b = b - \\alpha \\frac{\\partial J(w,b)}{\\partial b}$\n",
    "\n",
    "Onde:\n",
    "- $w$ e $b$ são atualizados simultaneamente em cada iteração\n",
    "- $\\alpha$ é a **taxa de aprendizado** (*learning rate*)\n",
    "- $\\frac{\\partial J(w,b)}{\\partial w}$ e $\\frac{\\partial J(w,b)}{\\partial b}$ são as derivadas parciais da função de custo\n",
    "\n",
    "### Taxa de Aprendizado (Learning Rate)\n",
    "\n",
    "A escolha de um bom valor para $\\alpha$ é crucial:\n",
    "\n",
    "- **$\\alpha$ muito pequeno**: O algoritmo dará passos muito curtos, tornando a convergência lenta e demorada\n",
    "- **$\\alpha$ muito grande**: O algoritmo pode \"saltar\" sobre o mínimo, falhando em convergir ou até divergindo\n",
    "\n",
    "![Learning Rate](../Assets/linear_regression/alpha.png)\n",
    "\n",
    "## Cálculo das Derivadas Parciais\n",
    "\n",
    "Para implementar o Gradient Descent, precisamos calcular as derivadas parciais da função de custo $J(w,b)$ com relação a $w$ e $b$. Começamos relembrando nossa função de custo:\n",
    "\n",
    "$J(w, b) = \\frac{1}{2m} \\sum_{i=1}^{m} (f(x_i) - y_i)^2$\n",
    "\n",
    "Como $f(x_i) = wx_i + b$, podemos reescrever:\n",
    "\n",
    "$J(w, b) = \\frac{1}{2m} \\sum_{i=1}^{m} ((wx_i + b) - y_i)^2$\n",
    "\n",
    "### Derivada Parcial com relação a $w$\n",
    "\n",
    "Aplicando a regra da cadeia para derivar $J(w,b)$ com relação a $w$:\n",
    "\n",
    "$\\frac{\\partial J(w,b)}{\\partial w} = \\frac{\\partial}{\\partial w} \\left[\\frac{1}{2m} \\sum_{i=1}^{m} ((wx_i + b) - y_i)^2\\right]$\n",
    "\n",
    "A constante $\\frac{1}{2m}$ pode sair da derivada:\n",
    "\n",
    "$\\frac{\\partial J(w,b)}{\\partial w} = \\frac{1}{2m} \\sum_{i=1}^{m} \\frac{\\partial}{\\partial w} ((wx_i + b) - y_i)^2$\n",
    "\n",
    "Aplicando a regra da cadeia: $\\frac{d}{dx}[g(x)]^2 = 2g(x) \\cdot g'(x)$\n",
    "\n",
    "$\\frac{\\partial J(w,b)}{\\partial w} = \\frac{1}{2m} \\sum_{i=1}^{m} 2((wx_i + b) - y_i) \\cdot \\frac{\\partial}{\\partial w}((wx_i + b) - y_i)$\n",
    "\n",
    "Como $\\frac{\\partial}{\\partial w}((wx_i + b) - y_i) = x_i$:\n",
    "\n",
    "$\\frac{\\partial J(w,b)}{\\partial w} = \\frac{1}{2m} \\sum_{i=1}^{m} 2((wx_i + b) - y_i) \\cdot x_i$\n",
    "\n",
    "O fator $2$ cancela com o $2$ do denominador:\n",
    "\n",
    "$\\frac{\\partial J(w,b)}{\\partial w} = \\frac{1}{m} \\sum_{i=1}^{m} x_i \\big((w x_i + b) - y_i\\big)$\n",
    "\n",
    "Substituindo $wx_i + b$ por $f(x_i)$:\n",
    "\n",
    "$\\boxed{\\frac{\\partial J(w,b)}{\\partial w} = \\frac{1}{m} \\sum_{i=1}^{m} x_i(f(x_i) - y_i) }$\n",
    "\n",
    "### Derivada Parcial com relação a $b$\n",
    "\n",
    "Seguindo o mesmo processo para $b$:\n",
    "\n",
    "$\\frac{\\partial J(w,b)}{\\partial b} = \\frac{\\partial}{\\partial b} \\left[\\frac{1}{2m} \\sum_{i=1}^{m} ((wx_i + b) - y_i)^2\\right]$\n",
    "\n",
    "$\\frac{\\partial J(w,b)}{\\partial b} = \\frac{1}{2m} \\sum_{i=1}^{m} \\frac{\\partial}{\\partial b} ((wx_i + b) - y_i)^2$\n",
    "\n",
    "Aplicando a regra da cadeia:\n",
    "\n",
    "$\\frac{\\partial J(w,b)}{\\partial b} = \\frac{1}{2m} \\sum_{i=1}^{m} 2((wx_i + b) - y_i) \\cdot \\frac{\\partial}{\\partial b}((wx_i + b) - y_i)$\n",
    "\n",
    "Como $\\frac{\\partial}{\\partial b}((wx_i + b) - y_i) = 1$:\n",
    "\n",
    "$\\frac{\\partial J(w,b)}{\\partial b} = \\frac{1}{2m} \\sum_{i=1}^{m} 2((wx_i + b) - y_i) \\cdot 1$\n",
    "\n",
    "Simplificando:\n",
    "\n",
    "$\\frac{\\partial J(w,b)}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^{m} ((wx_i + b) - y_i)$\n",
    "\n",
    "Substituindo $(wx_i + b)$ por $f(x_i)$:\n",
    "\n",
    "$\\boxed{\\frac{\\partial J(w,b)}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^{m} (f(x_i) - y_i)}$\n",
    "\n",
    "### Algoritmo Completo\n",
    "\n",
    "Com as derivadas calculadas, o algoritmo de Gradient Descent para Regressão Linear fica:\n",
    "\n",
    "**Repetir até convergência:**\n",
    "\n",
    "$w = w - \\alpha \\cdot \\frac{1}{m} \\sum_{i=1}^{m} x_i(f(x_i) - y_i) $\n",
    "\n",
    "$b = b - \\alpha \\cdot \\frac{1}{m} \\sum_{i=1}^{m} (f(x_i) - y_i)$\n",
    "\n",
    "Onde $f(x_i) = wx_i + b$\n",
    "\n",
    "> **Nota importante**: Os parâmetros $w$ e $b$ devem ser atualizados **simultaneamente** em cada iteração, ou seja, calculamos ambas as derivadas com os valores antigos antes de atualizar qualquer parâmetro.\n",
    "\n",
    "# Agora, abaixo terá um exemplo utilizando código Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6052bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações das Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af232dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação do nosso DataSet\n",
    "training_set = pd.read_csv('../Datasets/Salary_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4433a524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definições do nosso Parameter e Target\n",
    "X_train = training_set['YearsExperience'].values\n",
    "y_train = training_set['Salary'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fa6a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização Scatter do Parameter com o Target\n",
    "plt.scatter(X_train, y_train)\n",
    "plt.xlabel(\"Years of Experience\")\n",
    "plt.ylabel(\"Salary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e11051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precisamos de três funções principais para implementar a regressão linear:\n",
    "# 1) Cost function: Calcula o quão bom o modelo está, utilizando o Mean Squared Error (MSE), que mede o erro médio ao quadrado entre os valores previstos e os valores reais.\n",
    "#\n",
    "# 2) Gradient function: Calcula as derivadas da cost function em relação aos parâmetros w e b.\n",
    "#\n",
    "# 3) Gradient descent function: Utiliza os gradientes calculados pela gradient function para atualizar os parâmetros w e b a cada iteração, com o objetivo de minimizar o erro.\n",
    "\n",
    "def cost_function(x, y, w, b):\n",
    "    m = len(x)\n",
    "    cost_sum = 0\n",
    "\n",
    "    for i in range(m):\n",
    "        f = w * x[i] + b\n",
    "        cost = (f - y[i]) ** 2\n",
    "        cost_sum += cost\n",
    "\n",
    "    total_cost = (1/(2*m)) * cost_sum\n",
    "    return total_cost\n",
    "\n",
    "\n",
    "def gradient_function(x, y, w, b):\n",
    "    m = len(x)\n",
    "    dc_dw = 0\n",
    "    dc_db = 0\n",
    "\n",
    "    for i in range(m):\n",
    "        f = w * x[i] + b\n",
    "\n",
    "        dc_dw += (f - y[i]) * x[i]\n",
    "        dc_db += (f - y[i])\n",
    "\n",
    "    dc_dw = (1/m) * dc_dw\n",
    "    dc_db = (1/m) * dc_db\n",
    "\n",
    "    return dc_dw, dc_db\n",
    "\n",
    "\n",
    "def gradient_descent(x, y, alpha, iterations):\n",
    "    w = 0\n",
    "    b = 0\n",
    "\n",
    "    for i in range(iterations):\n",
    "        dc_dw, dc_db = gradient_function(x, y, w, b)\n",
    "\n",
    "        w = w - alpha * dc_dw\n",
    "        b = b - alpha * dc_db\n",
    "\n",
    "        print(f\"Iteration {i}: Cost {cost_function(x, y, w, b)}\")\n",
    "\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bf4294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indica o Learning Rate e a quantidade de iterations\n",
    "learning_rate = 0.01\n",
    "iterations = 10000\n",
    "# Calcula o Gradient Descent de fato\n",
    "final_w, final_b = gradient_descent(\n",
    "    X_train, y_train, learning_rate, iterations)\n",
    "print(f\"w: {final_w:.4f}, b: {final_b:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db6a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza a Linha de Regressão\n",
    "plt.scatter(X_train, y_train, label='Data Points')\n",
    "\n",
    "X_vals = np.linspace(min(X_train), max(X_train), 100)\n",
    "y_vals = final_w * X_vals + final_b\n",
    "plt.plot(X_vals, y_vals, color='red', label='Regression Line')\n",
    "\n",
    "plt.xlabel(\"Years of Experience\")\n",
    "plt.ylabel(\"Salary\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f69663",
   "metadata": {},
   "source": [
    "# Otimização da Regressão Linear\n",
    "\n",
    "## Introdução\n",
    "\n",
    "Após implementar o algoritmo básico de Regressão Linear com Gradient Descent, dois desafios comuns surgem na prática:\n",
    "\n",
    "1. **Valores de custo muito elevados** - Dificultando a interpretação e convergência\n",
    "2. **Escolha inadequada do learning rate** - Resultando em convergência lenta ou falha no treinamento\n",
    "\n",
    "Este guia apresenta duas técnicas essenciais para resolver esses problemas: **normalização de features** e **teste sistemático de learning rates**.\n",
    "\n",
    "---\n",
    "\n",
    "## Normalização de Features\n",
    "\n",
    "### O Problema da Escala\n",
    "\n",
    "Quando trabalhamos com dados em escalas diferentes, o algoritmo de Gradient Descent enfrenta dificuldades. Por exemplo, se uma feature varia entre 0 e 100 e outra entre 0 e 100.000, os gradientes terão magnitudes muito diferentes, causando:\n",
    "\n",
    "- **Convergência lenta**: O algoritmo precisa de muitas iterações\n",
    "- **Instabilidade numérica**: Valores de custo extremamente grandes\n",
    "- **Dificuldade em escolher o learning rate**: Um α que funciona para uma feature pode ser inadequado para outra\n",
    "\n",
    "### Solução: Z-Score Normalization\n",
    "\n",
    "A normalização por **z-score** transforma os dados para que tenham média 0 e desvio padrão 1:\n",
    "\n",
    "$$X_{norm} = \\frac{X - \\mu}{\\sigma}$$\n",
    "\n",
    "Onde:\n",
    "- $\\mu$ é a média dos dados\n",
    "- $\\sigma$ é o desvio padrão dos dados\n",
    "\n",
    "### Implementação\n",
    "\n",
    "```python\n",
    "def normalize_features(X):\n",
    "    \"\"\"Normaliza os dados usando z-score\"\"\"\n",
    "    mean = np.mean(X)\n",
    "    std = np.std(X)\n",
    "    X_norm = (X - mean) / std\n",
    "    return X_norm\n",
    "```\n",
    "\n",
    "**Parâmetros:**\n",
    "- `X`: Array com os dados originais\n",
    "\n",
    "**Retorno:**\n",
    "- `X_norm`: Dados normalizados\n",
    "\n",
    "### Benefícios da Normalização\n",
    "\n",
    "1. **Redução drástica do custo**: De milhões para valores próximos de 0\n",
    "2. **Convergência mais rápida**: Menos iterações necessárias\n",
    "3. **Gradientes balanceados**: Todas as features contribuem igualmente\n",
    "4. **Facilita a escolha do learning rate**: Valores típicos (0.01 a 1.0) funcionam bem\n",
    "\n",
    "### Exemplo Prático\n",
    "\n",
    "Antes da normalização:\n",
    "```\n",
    "X: min=1.10, max=10.50, mean=5.31\n",
    "y: min=$37,731, max=$122,391, mean=$76,003\n",
    "Custo inicial: 1,344,612,525\n",
    "```\n",
    "\n",
    "Depois da normalização:\n",
    "```\n",
    "X_norm: min=-1.51, max=1.86, mean=0.00\n",
    "y_norm: min=-1.42, max=1.72, mean=0.00\n",
    "Custo inicial: 0.499\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Otimização do Learning Rate\n",
    "\n",
    "### O Dilema do Learning Rate\n",
    "\n",
    "O learning rate ($\\alpha$) controla o tamanho dos passos que o algoritmo dá em direção ao mínimo. A escolha deste valor é crítica:\n",
    "\n",
    "| Learning Rate | Comportamento | Resultado |\n",
    "|---------------|---------------|-----------|\n",
    "| **Muito pequeno** | Passos minúsculos | Convergência muito lenta |\n",
    "| **Adequado** | Passos balanceados | Convergência eficiente |\n",
    "| **Muito grande** | Passos excessivos | Oscilação ou divergência |\n",
    "\n",
    "### Estratégia de Teste Sistemático\n",
    "\n",
    "Em vez de escolher arbitrariamente, testamos vários valores e selecionamos o melhor baseado em métricas de performance.\n",
    "\n",
    "### Implementação\n",
    "\n",
    "```python\n",
    "def test_learning_rates(X, y):\n",
    "    \"\"\"Testa diferentes learning rates para encontrar o melhor\"\"\"\n",
    "    learning_rates = [0.001, 0.01, 0.1, 0.5, 1.0]\n",
    "    iterations = 5000\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(\"TESTANDO DIFERENTES LEARNING RATES\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for lr in learning_rates:\n",
    "        print(f\"\\n--- Testing α = {lr} ---\")\n",
    "        w, b, history = gradient_descent(\n",
    "            X, y, lr, iterations, print_every=1000)\n",
    "\n",
    "        # Calcula R²\n",
    "        predictions = w * X + b\n",
    "        ss_res = np.sum((y - predictions) ** 2)\n",
    "        ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "        r2 = 1 - (ss_res / ss_tot)\n",
    "\n",
    "        results.append({\n",
    "            'lr': lr,\n",
    "            'final_cost': history[-1],\n",
    "            'r2': r2,\n",
    "            'w': w,\n",
    "            'b': b\n",
    "        })\n",
    "\n",
    "        print(f\"Final cost: {history[-1]:.6f}, R²: {r2:.4f}\")\n",
    "\n",
    "    # Seleciona o melhor resultado\n",
    "    best = max(results, key=lambda x: x['r2'])\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"MELHOR LEARNING RATE: α = {best['lr']}\")\n",
    "    print(f\"R² = {best['r2']:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    return best['lr']\n",
    "```\n",
    "\n",
    "### Detalhamento do Código\n",
    "\n",
    "#### 1. Definição dos Candidatos\n",
    "\n",
    "```python\n",
    "learning_rates = [0.001, 0.01, 0.1, 0.5, 1.0]\n",
    "```\n",
    "\n",
    "Testamos valores em **escala logarítmica**, cobrindo desde valores muito conservadores até agressivos.\n",
    "\n",
    "#### 2. Treinamento com Cada Candidato\n",
    "\n",
    "```python\n",
    "for lr in learning_rates:\n",
    "    w, b, history = gradient_descent(X, y, lr, iterations, print_every=1000)\n",
    "```\n",
    "\n",
    "Cada learning rate é testado com o mesmo número de iterações para comparação justa.\n",
    "\n",
    "#### 3. Cálculo do R² Score\n",
    "\n",
    "O **coeficiente de determinação** ($R^2$) mede o quão bem o modelo explica a variabilidade dos dados:\n",
    "\n",
    "$$R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}$$\n",
    "\n",
    "Onde:\n",
    "- $SS_{res} = \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2$ (soma dos quadrados dos resíduos)\n",
    "- $SS_{tot} = \\sum_{i=1}^{m} (y_i - \\bar{y})^2$ (soma total dos quadrados)\n",
    "\n",
    "```python\n",
    "predictions = w * X + b\n",
    "ss_res = np.sum((y - predictions) ** 2)\n",
    "ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "r2 = 1 - (ss_res / ss_tot)\n",
    "```\n",
    "\n",
    "#### Interpretação do R²:\n",
    "\n",
    "- R² = 1.0: Modelo perfeito (explica 100% da variância)\n",
    "- R² = 0.95: Excelente (explica 95% da variância)\n",
    "- R² = 0.70: Bom (explica 70% da variância)\n",
    "- R² = 0.50: Médio (explica 50% da variância)\n",
    "- R² < 0.30: Ruim (modelo pouco preditivo)\n",
    "- R² < 0: Modelo pior que simplesmente usar a média\n",
    "\n",
    "#### 4. Armazenamento dos Resultados\n",
    "\n",
    "```python\n",
    "pythonresults.append({\n",
    "    'lr': lr,\n",
    "    'final_cost': history[-1],\n",
    "    'r2': r2,\n",
    "    'w': w,\n",
    "    'b': b\n",
    "})\n",
    "```\n",
    "\n",
    "Cada teste é armazenado em um dicionário contendo todas as métricas relevantes.\n",
    "\n",
    "#### 5. Seleção do Melhor Learning Rate\n",
    "\n",
    "```python\n",
    "pythonbest = max(results, key=lambda x: x['r2'])\n",
    "```\n",
    "\n",
    "Utilizamos o R² como critério de seleção, escolhendo o learning rate que maximiza esta métrica.\n",
    "\n",
    "# Código na Prática!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f032d879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código Bônus - Normalização e Learning Rate Adequado\n",
    "\n",
    "def normalize_features(X):\n",
    "    \"\"\"Normaliza os dados usando z-score\"\"\"\n",
    "    mean = np.mean(X)\n",
    "    std = np.std(X)\n",
    "    X_norm = (X - mean) / std\n",
    "    return X_norm, mean, std\n",
    "\n",
    "\n",
    "def test_learning_rates(X, y):\n",
    "    \"\"\"Testa diferentes learning rates para encontrar o melhor\"\"\"\n",
    "    learning_rates = [0.001, 0.01, 0.1, 0.5, 1.0]\n",
    "    iterations = 5000\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(\"TESTANDO DIFERENTES LEARNING RATES\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for lr in learning_rates:\n",
    "        print(f\"\\n--- Testing α = {lr} ---\")\n",
    "        w, b = gradient_descent(\n",
    "            X, y, lr, iterations)\n",
    "\n",
    "        # R²\n",
    "        predictions = w * X + b\n",
    "        ss_res = np.sum((y - predictions) ** 2)\n",
    "        ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "        r2 = 1 - (ss_res / ss_tot)\n",
    "\n",
    "        results.append({\n",
    "            'lr': lr,\n",
    "            'r2': r2,\n",
    "            'w': w,\n",
    "            'b': b\n",
    "        })\n",
    "\n",
    "        print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "    # Melhor resultado\n",
    "    best = max(results, key=lambda x: x['r2'])\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"MELHOR LEARNING RATE: α = {best['lr']}\")\n",
    "    print(f\"R² = {best['r2']:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    return best['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e4597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliza os dados\n",
    "X_norm, x_mean, x_std = normalize_features(X_train)\n",
    "y_norm, y_mean, y_std = normalize_features(y_train)\n",
    "\n",
    "print(\"\\nDADOS NORMALIZADOS\")\n",
    "print(\n",
    "    f\"X_norm: min={X_norm.min():.2f}, max={X_norm.max():.2f}, mean={X_norm.mean():.2f}\")\n",
    "print(\n",
    "    f\"y_norm: min={y_norm.min():.2f}, max={y_norm.max():.2f}, mean={y_norm.mean():.2f}\")\n",
    "\n",
    "# Testa diferentes learning rates\n",
    "best_lr = test_learning_rates(X_norm, y_norm)\n",
    "\n",
    "# Treina novamente só que agora com o melhor learning rate\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"TREINAMENTO FINAL COM α = {best_lr}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "w_initial = 0\n",
    "b_initial = 0\n",
    "iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d899722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz o Gradient Descent agora com o custo muito menor (melhor)\n",
    "w_final, b_final = gradient_descent(\n",
    "    X_norm, y_norm, best_lr, iterations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20979985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para visualizar a Regression Line\n",
    "def plot_regression(X, y, w, b):\n",
    "    \"\"\"Plota dados e linha de regressão - BEM SIMPLES\"\"\"\n",
    "\n",
    "    # Calcula predições\n",
    "    predictions = w * X + b\n",
    "\n",
    "    # Plota\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(X, y, color='blue', s=100, alpha=0.6, label='Dados')\n",
    "    plt.plot(X, predictions, color='red', linewidth=3, label='Regressão')\n",
    "\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('y')\n",
    "    plt.title(f'Regressão Linear: y = {w:.4f}x + {b:.4f}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_regression(X_norm, y_norm, w_final, b_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c05311a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
