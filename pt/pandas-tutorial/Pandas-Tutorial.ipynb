{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54b831ce",
   "metadata": {},
   "source": [
    "# Welcome to the Pandas Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea65881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Em Jupyter, usamos \"!\" para rodar comandos de CLI\n",
    "# No c√≥digo abaixo, buscamos onde que est√° rodando nosso Python\n",
    "!where python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d583e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d694e0cb",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27a60a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ce40f9",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb897ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui transforma o arquivo csv em um DataFrame (basicamente uma table de um database ou uma planilha de Excel)\n",
    "df = pd.read_csv('../../Datasets/world-happiness/2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11c7b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3087cc44",
   "metadata": {},
   "source": [
    "## Inspect Data\n",
    "\n",
    "### Look at the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3ab865",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f944582",
   "metadata": {},
   "source": [
    "### Look at the shape of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f9c857",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows, num_cols = df.shape\n",
    "print(f\"Number of rows: {num_rows}\\nNumber of Cols: {num_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44840d6",
   "metadata": {},
   "source": [
    "### Checking the data types of our columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383cbd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfda1db0",
   "metadata": {},
   "source": [
    "### Describe the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7420ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e87dece",
   "metadata": {},
   "source": [
    "### Info of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5906152",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f642e713",
   "metadata": {},
   "source": [
    "# The Difference Between Pandas Series and DataFrame\n",
    "\n",
    "Pandas provides two main data structures:\n",
    "\n",
    "- **Series**: a one-dimensional labeled array\n",
    "- **DataFrame**: a two-dimensional labeled table\n",
    "\n",
    "Understanding the difference between them is fundamental for data analysis, data science, and machine learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51efd6c",
   "metadata": {},
   "source": [
    "## 1. Pandas Series\n",
    "\n",
    "A **Series** is a one-dimensional data structure.\n",
    "It represents a single column of data with an associated index.\n",
    "\n",
    "Key characteristics:\n",
    "- One-dimensional\n",
    "- Has values and an index\n",
    "- Similar to a column in Excel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9696983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type of a Column\n",
    "type(df['Country or region'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e670cf",
   "metadata": {},
   "source": [
    "## 2. Pandas DataFrame\n",
    "\n",
    "A **DataFrame** is a two-dimensional data structure made of multiple Pandas Series.\n",
    "\n",
    "Each column in a DataFrame is a Series, and all Series share the same index.\n",
    "\n",
    "Key characteristics:\n",
    "- Two-dimensional (rows and columns)\n",
    "- Different columns can have different data types\n",
    "- Similar to an Excel spreadsheet or SQL table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2196ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type of a DataFrame\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b442b95a",
   "metadata": {},
   "source": [
    "## 3. Relationship Between DataFrame and Series\n",
    "\n",
    "A very important concept:\n",
    "\n",
    "- A DataFrame column is a Pandas Series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2f819f",
   "metadata": {},
   "source": [
    "# Section #1 - Working with one dataset\n",
    "\n",
    "## Question #1 - What is the average, min, and max happiness score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69471576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case, we can use the describe method in the Score Column\n",
    "df['Score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c2dbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otherwise, we can use different methods, like 'mean', 'min', 'max'.\n",
    "mean_score = df['Score'].mean()\n",
    "min_score = df['Score'].min()\n",
    "max_score = df['Score'].max()\n",
    "\n",
    "print(\n",
    "    f\"The answer is:\\nAverage:{mean_score:.4}\\nMin:{min_score}\\nMax:{max_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6770218b",
   "metadata": {},
   "source": [
    "## Question #2 - What is the score for the Brazil?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e401df",
   "metadata": {},
   "source": [
    "### Option #1 - Use Bracket notation filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348b418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22577c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask\n",
    "brazil_boolean_mask = df['Country or region'] == 'Brazil'\n",
    "brazil_boolean_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372e727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[brazil_boolean_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8685ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's only one row, but it stills a DataFrame\n",
    "type(df[brazil_boolean_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1204bad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we can use methods of DataFrames, in this example, we're going to get the Score of Brazil\n",
    "brazil_score = df[brazil_boolean_mask]['Score']\n",
    "\n",
    "print(f\"The Score of Brazil is: {brazil_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802f9b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It returns an Panda Series, to access the value itself we have to do this way, which return an numpy array\n",
    "brazil_score = df[brazil_boolean_mask]['Score'].values\n",
    "\n",
    "print(f\"The Score of Brazil is: {brazil_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a4cb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So to filter only the value itself, we pass the [0]\n",
    "brazil_score = df[brazil_boolean_mask]['Score'].values[0]\n",
    "\n",
    "print(f\"The Score of Brazil is: {brazil_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a81fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In only one line of code\n",
    "df[df['Country or region'] == 'Brazil']['Score'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef83c80",
   "metadata": {},
   "source": [
    "### Option #2 - Use Indices with _.iloc_ and _.loc_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689ebfbe",
   "metadata": {},
   "source": [
    "**_iloc is a way to access data in a DataFrame by the numeric position of the rows and columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57e1c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index 0, second column\n",
    "df.iloc[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebcdf7f",
   "metadata": {},
   "source": [
    "**_loc is a way to access data in a Dataframe by the name of the Index and the Column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeb7ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we have to alter the index to the Country Name\n",
    "country_name_index = df.set_index(['Country or region'])\n",
    "country_name_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea17840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we pass the .loc method to return the filtered row\n",
    "country_name_index.loc['Brazil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6a4bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can improve the filter passing the Column name\n",
    "country_name_index.loc['Brazil', 'Score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1783350",
   "metadata": {},
   "source": [
    "## Question #3 - What is the country with highest Generosity score?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb1c3dc",
   "metadata": {},
   "source": [
    "### Option #1 - Use sort values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbebbcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_generosity_country = df.sort_values(\n",
    "    by='Generosity', ascending=False).iloc[0, 1]\n",
    "\n",
    "print(\n",
    "    f'The country with the Highest Generosity is: {highest_generosity_country}.\\nThe Generosity there is: {country_name_index.loc['Myanmar', 'Generosity']}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4cbc78",
   "metadata": {},
   "source": [
    "### Option #2 - Use argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6a6550",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_generosity_idx = df['Generosity'].argmax()\n",
    "df.iloc[max_generosity_idx, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f10f6e",
   "metadata": {},
   "source": [
    "## Question #4 - What does the distribution of happiness scores look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a42b2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_column = df['Score']\n",
    "score_column.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf34c29d",
   "metadata": {},
   "source": [
    "## Question #5 - What does the distribution of all our columns look like?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fa15f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assign it in some throwaray variable, the conventional is underscore '_'\n",
    "_ = df.hist(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37057a8e",
   "metadata": {},
   "source": [
    "## Question #5 - What is the relationship between social support and happiness score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3cdcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='Social support', y='Score',\n",
    "        title='Relationship between social support and happiness', kind='scatter', figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dc04cb",
   "metadata": {},
   "source": [
    "## Question #6 - What if we wanted to have the Score go from 0 to 100 rather than 0 to 10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58752f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7720ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Score out of 100'] = df['Score'] * 10\n",
    "\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d934e9a5",
   "metadata": {},
   "source": [
    "# Section #2 - Concatenating multiple datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0b72c8",
   "metadata": {},
   "source": [
    "## Question #8 - I have multiple datasets that I want to combine, how can I bring them all together?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f61406",
   "metadata": {},
   "source": [
    "### Step #1 - Load all of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff144f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26bfff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = glob.glob('../../Datasets/world-happiness/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23848bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325473a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in file_names:\n",
    "    data = pd.read_csv(f)\n",
    "    year = f[-8:-4]\n",
    "    dfs[year] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32614fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87b87fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['2019']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08250125",
   "metadata": {},
   "source": [
    "## Step #2 - Look at the shape of each year's DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872a563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, data in dfs.items():\n",
    "    print(f'{year}: {data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3f62b1",
   "metadata": {},
   "source": [
    "## Step #3 - Add a 'Year' column to each DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8e7eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, data in dfs.items():\n",
    "    print(f\"{year}: {data.head(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f16a73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, data in dfs.items():\n",
    "    dfs[year]['Year'] = year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82bc05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['2015'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfc754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['2018'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9653965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['2019'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26b7dcf",
   "metadata": {},
   "source": [
    "## Step #4 - Combine data for years 2019 and 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3de44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bd6540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the 'set' to see the differences of two dataframes, as an example:\n",
    "set([2, 3, 4]) ^ set([4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093e2ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['2018'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669a1d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['2019'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6b9e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's see if our columns are different or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d71fd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(dfs['2018'].columns) ^ set(dfs['2019'].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbd6a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the two DataFrames\n",
    "df_concat = pd.concat([dfs['2018'], dfs['2019']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a600acba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we can see that the concat uses the same index, to fix this, we have to pass 'ignore_index' to True, the default is False\n",
    "df_concat.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d03b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the two DataFrames\n",
    "df_concat = pd.concat([dfs['2018'], dfs['2019']], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217fe54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74b1438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7453c93c",
   "metadata": {},
   "source": [
    "### Step #5 - Combine data for years 2019, 2018, and 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169aa4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(dfs['2019'].columns) ^ set(dfs['2015'].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6458f381",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['2019'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04932bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['2015'].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0616a7f",
   "metadata": {},
   "source": [
    "### Change the Name of The Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55f25ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d98448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_columns = list(df_copy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e873abe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = old_columns.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f67ab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns[0] = 'RANK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5194b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae426c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59801ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.columns = new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c3e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed9e04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['2019'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fe8cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['2015'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99921479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In our example\n",
    "new_2015_column_names = [\n",
    "    \"Country or region\", \"Region\", \"Overall rank\", \"Score\", \"Standard Error\", \"GDP per capita\",\n",
    "    \"Social support\", \"Healthy life expectancy\", \"Freedom to make life choices\", \"Perception of corruption\", \"Generosity\", \"Dystopia Residual\", \"Year\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a952fcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['2015'].columns = new_2015_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42594c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat(\n",
    "    [dfs['2015'], dfs['2019'], dfs['2018']], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c624ff28",
   "metadata": {},
   "source": [
    "## As an exercise: Concat the 2016 and 2017 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d64fe79",
   "metadata": {},
   "source": [
    "## Question #9 - It looks like we have Region Data for 2015, but not for 2018 or 2019, is there a way to bring in Region data for the years we dont have it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db2aff9",
   "metadata": {},
   "source": [
    "### Option #1 - Mapping (we're not going to use this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f022bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_concat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164aea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_mapping_dict = {\n",
    "    \"Rwanda\": \"Sub-Saharan Africa\",\n",
    "    \"Syria\": \"Middle East and Northern Africa\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6a4351",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Country or region'].map(region_mapping_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafccc5d",
   "metadata": {},
   "source": [
    "### Option #2 - Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ee62ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['2015'][['Country or region', 'Region']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edf64ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_mapping_df = dfs['2015'][['Country or region', 'Region']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da73aa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4539fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left=df_concat, right=region_mapping_df,\n",
    "         how=\"right\", on=\"Country or region\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d86dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See that it creates two columns, x and y, to fix this, we have to drop the column Region\n",
    "df_concat = df_concat.drop(columns='Region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f04500",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_with_region = pd.merge(left=df_concat, right=region_mapping_df,\n",
    "                                 how=\"right\", on=\"Country or region\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4772c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_with_region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c60335",
   "metadata": {},
   "source": [
    "## Question #9b - Are there any regions that didn't match up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0235aca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_with_region['Region'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9cba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_region_mask = df_concat_with_region['Region'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92430f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_with_region[no_region_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436f94b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_region_mask.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96042c53",
   "metadata": {},
   "source": [
    "## Question #10 - Now that we have a nice combined dataset, how do we write it back out to a file for later usage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fed95c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_with_region.to_csv('combined-happiness-score.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90106f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4a3637",
   "metadata": {},
   "source": [
    "# Section #3 - Working with our new data from multiple years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8099aa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_with_region.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d97f880",
   "metadata": {},
   "source": [
    "## Question #11 - How many countries do we have per Region?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33937f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This results of duplicates Regions, because there are multiple years\n",
    "df_concat_with_region['Region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a01ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_one_year_mask = df_concat_with_region['Year'] == '2019'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c575cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To really get all the countries per Region, we have to filter one year only\n",
    "df_concat_with_region[only_one_year_mask]['Region'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ae9606",
   "metadata": {},
   "source": [
    "## Question #12 - What is the average happiness score by region?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c91aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_happiness_region = df_concat_with_region[[\n",
    "    'Region', 'Score']].groupby('Region').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1bbec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_happiness_region.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd4384d",
   "metadata": {},
   "source": [
    "## Question #13 - What is the average happiness score over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b991faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_with_region['Year'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1537d63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_with_region['Year'] = df_concat_with_region['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb64f4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_with_region.groupby('Year').mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae03526",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_happiness_over_time = df_concat_with_region.groupby(\n",
    "    'Year').mean(numeric_only=True)['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb10fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_happiness_over_time.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07e5efc",
   "metadata": {},
   "source": [
    "## Question #14 - In 2019, how many countries in Africa (sub-Saharan and Northern/Middle East) have a happiness score higher than the lowest score in Western Europe?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea309461",
   "metadata": {},
   "source": [
    "**First, let's get only the year 2019**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f8976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_2019_mask = df_concat_with_region['Year'] == 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e1fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_only_2019 = df_concat_with_region[year_2019_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abec242",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_only_2019.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb34de0",
   "metadata": {},
   "source": [
    "**Then, let's find the lowest score in Western Europe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0869f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "western_europe_2019_mask = df_only_2019['Region'] == 'Western Europe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975dc999",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_western_europe_2019 = df_only_2019[western_europe_2019_mask]['Score'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8016d8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_score_western_europe = score_western_europe_2019.min()\n",
    "\n",
    "print(f'Lowest Score in Western Europe: {lowest_score_western_europe}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a2a847",
   "metadata": {},
   "source": [
    "**With this, we can filter the Countries in Africa that has higher score than the lowest score in Western Europe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f455e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_only_2019['Region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28bd2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "africa_2019_mask = (\n",
    "    (df_only_2019['Region'] == 'Middle East and Northern Africa') |\n",
    "    (df_only_2019['Region'] == 'Sub-Saharan Africa')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbb1fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "african_countries_2019 = df_only_2019[africa_2019_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9639ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "african_countries_2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257ba966",
   "metadata": {},
   "outputs": [],
   "source": [
    "african_countries_score_higher_than_western_europe = african_countries_2019[\n",
    "    'Score'] > lowest_score_western_europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cae52b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(african_countries_2019[african_countries_score_higher_than_western_europe]\n",
    "    ['Country or region'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4818bdf1",
   "metadata": {},
   "source": [
    "## Question #15 - Can we look at the change in average happiness levels by region over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9555711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_with_region.groupby(['Year', 'Region'])['Score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dae50e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use unstack to change the index to Year and the Columns to Regions\n",
    "df_concat_with_region.groupby(['Year', 'Region'])[\n",
    "    'Score'].mean().unstack(level=0).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd4d450",
   "metadata": {},
   "source": [
    "## Question #16 - Which countries had their score increase the most over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f55dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_with_region.pivot_table(\n",
    "    values='Score', index='Country or region', columns='Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc83429",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_countries_over_time = df_concat_with_region.pivot_table(\n",
    "    values='Score', index='Country or region', columns='Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aae88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_countries_over_time['Difference'] = df_countries_over_time[2019] - \\\n",
    "    df_countries_over_time[2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bba6ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_countries_over_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33abd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_countries_over_time.sort_values(by='Difference', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a903f67",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "1. See about getting 2016 and 2017 data into our DataFrame.\n",
    "2. Join in some additional data to this dataset using pd.merge. For example, population data.\n",
    "3. Find your own dataset to play with!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0283fd6e",
   "metadata": {},
   "source": [
    "# üêº Pandas Extra Tips\n",
    "## T√©cnicas Essenciais de Limpeza de Dados\n",
    "\n",
    "---\n",
    "\n",
    "## √çndice\n",
    "1. Setup e Dataset\n",
    "2. Remove Duplicates (Remover Duplicatas)\n",
    "3. Strip Values (Remover Espa√ßos)\n",
    "4. Splitting Columns (Dividir Colunas)\n",
    "5. Replace (Substituir Valores)\n",
    "6. Fill NA (Preencher Valores Nulos)\n",
    "7. Combinando T√©cnicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0217655b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88eb0d00",
   "metadata": {},
   "source": [
    "---\n",
    "## Criando Dataset de Exemplo\n",
    "\n",
    "Vamos criar um dataset com problemas comuns de dados \"sujos\":\n",
    "- Duplicatas\n",
    "- Espa√ßos em branco\n",
    "- Colunas que precisam ser divididas\n",
    "- Valores inconsistentes\n",
    "- Valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09daf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Criar dataset \"sujo\" para praticar limpeza\n",
    "data = {\n",
    "    'customer_id': [1, 2, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10],\n",
    "    'name': ['  John Doe  ', 'Jane Smith', 'Jane Smith', '  Bob Johnson',\n",
    "             'Alice Brown  ', 'Charlie Wilson', 'Charlie Wilson', 'Diana Prince',\n",
    "             'Eve Adams', 'Frank Miller', '  Grace Lee', 'Henry Ford  '],\n",
    "    'email_phone': ['john@email.com|555-0100', 'jane@email.com|555-0101',\n",
    "                    'jane@email.com|555-0101', 'bob@email.com|555-0102',\n",
    "                    'alice@email.com|555-0103', 'charlie@email.com|555-0104',\n",
    "                    'charlie@email.com|555-0104', 'diana@email.com|555-0105',\n",
    "                    'eve@email.com|555-0106', 'frank@email.com|555-0107',\n",
    "                    'grace@email.com|555-0108', 'henry@email.com|555-0109'],\n",
    "    'status': ['Active', 'active', 'active', 'INACTIVE', 'Active',\n",
    "               'Inactive', 'Inactive', 'active', 'ACTIVE', 'inactive',\n",
    "               'Active', 'Active'],\n",
    "    'purchase_amount': [100.50, 250.00, 250.00, np.nan, 450.75,\n",
    "                        125.30, 125.30, 890.00, np.nan, 340.20,\n",
    "                        np.nan, 560.80],\n",
    "    'city_state': ['New York, NY', 'Los Angeles, CA', 'Los Angeles, CA',\n",
    "                   'Chicago, IL', 'Houston, TX', 'Phoenix, AZ', 'Phoenix, AZ',\n",
    "                   'Philadelphia, PA', 'San Antonio, TX', 'San Diego, CA',\n",
    "                   'Dallas, TX', 'San Jose, CA']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Dataset criado com {len(df)} linhas!\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c9e03f",
   "metadata": {},
   "source": [
    "**Problemas neste dataset:**\n",
    "- ‚ùå Linhas duplicadas (customer_id 2 e 5)\n",
    "- ‚ùå Espa√ßos em branco nos nomes\n",
    "- ‚ùå Email e telefone na mesma coluna\n",
    "- ‚ùå Status com capitaliza√ß√£o inconsistente\n",
    "- ‚ùå Valores nulos em purchase_amount\n",
    "- ‚ùå Cidade e estado juntos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6caba0",
   "metadata": {},
   "source": [
    "### Verificar duplicatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0793422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver quais linhas s√£o duplicadas\n",
    "print(\"\\nLinhas duplicadas:\")\n",
    "df[df.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7529922",
   "metadata": {},
   "source": [
    "### Remover duplicatas - M√©todo 1: Todas as colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336d2c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover duplicatas considerando TODAS as colunas\n",
    "df_no_dup = df.drop_duplicates()\n",
    "\n",
    "print(f\"Linhas antes: {len(df)}\")\n",
    "print(f\"Linhas depois: {len(df_no_dup)}\")\n",
    "print(f\"Linhas removidas: {len(df) - len(df_no_dup)}\")\n",
    "\n",
    "df_no_dup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f15af7e",
   "metadata": {},
   "source": [
    "### Remover duplicatas - M√©todo 2: Baseado em colunas espec√≠ficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d881df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover duplicatas baseado apenas no customer_id\n",
    "df_no_dup_id = df.drop_duplicates(subset=['customer_id'])\n",
    "\n",
    "print(f\"Linhas antes: {len(df)}\")\n",
    "print(f\"Linhas depois: {len(df_no_dup_id)}\")\n",
    "print(f\"Linhas removidas: {len(df) - len(df_no_dup_id)}\")\n",
    "\n",
    "df_no_dup_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739c63c3",
   "metadata": {},
   "source": [
    "### Escolher qual duplicata manter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71011c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manter a primeira ocorr√™ncia (padr√£o)\n",
    "df_keep_first = df.drop_duplicates(subset=['customer_id'], keep='first')\n",
    "print(\"Mantendo PRIMEIRA ocorr√™ncia:\")\n",
    "print(df_keep_first[df_keep_first['customer_id'].isin([2, 5])])\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Manter a √∫ltima ocorr√™ncia\n",
    "df_keep_last = df.drop_duplicates(subset=['customer_id'], keep='last')\n",
    "print(\"Mantendo √öLTIMA ocorr√™ncia:\")\n",
    "print(df_keep_last[df_keep_last['customer_id'].isin([2, 5])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865ca6fe",
   "metadata": {},
   "source": [
    "### Dica: Remover duplicatas in-place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946d729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar c√≥pia para demonstra√ß√£o\n",
    "df_copy = df.copy()\n",
    "\n",
    "# Remover duplicatas modificando o pr√≥prio dataframe\n",
    "df_copy.drop_duplicates(subset=['customer_id'], inplace=True)\n",
    "\n",
    "print(f\"Linhas ap√≥s drop_duplicates com inplace=True: {len(df_copy)}\")\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb0f9bd",
   "metadata": {},
   "source": [
    "---\n",
    "## Strip Values (Remover Espa√ßos)\n",
    "\n",
    "### Objetivo:\n",
    "Remover espa√ßos em branco no in√≠cio e fim de strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9b9b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos trabalhar com df_no_dup_id (sem duplicatas)\n",
    "df_clean = df_no_dup_id.copy()\n",
    "\n",
    "print(\"ANTES do strip:\")\n",
    "print(df_clean['name'].head())\n",
    "print(\"\\nRepare nos espa√ßos:\")\n",
    "for name in df_clean['name'].head():\n",
    "    print(f\"'{name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8343b0",
   "metadata": {},
   "source": [
    "### Strip com .str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735408d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar strip na coluna name\n",
    "df_clean['name'] = df_clean['name'].str.strip()\n",
    "\n",
    "print(\"\\nDEPOIS do strip:\")\n",
    "for name in df_clean['name'].head():\n",
    "    print(f\"'{name}'\")\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c616b03",
   "metadata": {},
   "source": [
    "---\n",
    "## Splitting Columns (Dividir Colunas)\n",
    "\n",
    "### Objetivo:\n",
    "Separar uma coluna em m√∫ltiplas colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1944206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coluna email_phone ANTES da divis√£o:\")\n",
    "print(df_clean['email_phone'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06891a05",
   "metadata": {},
   "source": [
    "### M√©todo 1: Split com .str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b016afd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir email_phone em duas colunas\n",
    "df_clean[['email', 'phone']] = df_clean['email_phone'].str.split(\n",
    "    '|', expand=True)\n",
    "\n",
    "print(\"\\nDEPOIS da divis√£o:\")\n",
    "print(df_clean[['email_phone', 'email', 'phone']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47f13bd",
   "metadata": {},
   "source": [
    "### M√©todo 2: Split de city_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0720bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir city_state em city e state\n",
    "df_clean[['city', 'state']] = df_clean['city_state'].str.split(\n",
    "    ', ', expand=True)\n",
    "\n",
    "print(\"City e State separados:\")\n",
    "print(df_clean[['city_state', 'city', 'state']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ff86bd",
   "metadata": {},
   "source": [
    "### Remover coluna original ap√≥s split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c0e200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover colunas que j√° foram divididas\n",
    "df_clean = df_clean.drop(columns=['email_phone', 'city_state'])\n",
    "\n",
    "print(\"‚úÖ Colunas removidas!\")\n",
    "print(f\"\\nColunas atuais: {df_clean.columns.tolist()}\")\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f128df",
   "metadata": {},
   "source": [
    "---\n",
    "## Replace (Substituir Valores)\n",
    "\n",
    "### Objetivo:\n",
    "Substituir valores espec√≠ficos ou padr√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e28f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coluna 'status' ANTES do replace:\")\n",
    "print(df_clean['status'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1d67da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituir valores individuais\n",
    "df_clean['status'] = df_clean['status'].replace({\n",
    "    'active': 'Active',\n",
    "    'ACTIVE': 'Active',\n",
    "    'inactive': 'Inactive',\n",
    "    'INACTIVE': 'Inactive'\n",
    "})\n",
    "\n",
    "print(\"\\nDEPOIS do replace:\")\n",
    "print(df_clean['status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b059f5d",
   "metadata": {},
   "source": [
    "---\n",
    "## Fill NA (Preencher Valores Nulos)\n",
    "\n",
    "### Objetivo:\n",
    "Tratar valores nulos (NaN) no dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f5dd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores nulos\n",
    "print(\"VALORES NULOS POR COLUNA:\")\n",
    "print(df_clean.isnull().sum())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"\\nTotal de valores nulos: {df_clean.isnull().sum().sum()}\")\n",
    "print(\n",
    "    f\"Percentual de dados faltantes: {(df_clean.isnull().sum().sum() / df_clean.size * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8399c371",
   "metadata": {},
   "source": [
    "### Visualizar linhas com valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d2a3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLinhas com valores nulos em purchase_amount:\")\n",
    "df_clean[df_clean['purchase_amount'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059b9158",
   "metadata": {},
   "source": [
    "### M√©todo 1: Preencher com valor espec√≠fico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f520eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencher com 0\n",
    "df_fill_zero = df_clean.copy()\n",
    "df_fill_zero['purchase_amount'] = df_fill_zero['purchase_amount'].fillna(0)\n",
    "\n",
    "print(\"Preenchido com 0:\")\n",
    "print(df_fill_zero[['name', 'purchase_amount']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3fe81a",
   "metadata": {},
   "source": [
    "### M√©todo 2: Preencher com m√©dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa86312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencher com a m√©dia\n",
    "df_fill_mean = df_clean.copy()\n",
    "mean_value = df_fill_mean['purchase_amount'].mean()\n",
    "df_fill_mean['purchase_amount'] = df_fill_mean['purchase_amount'].fillna(\n",
    "    mean_value)\n",
    "\n",
    "print(f\"M√©dia calculada: ${mean_value:.2f}\")\n",
    "print(\"\\nPreenchido com m√©dia:\")\n",
    "print(df_fill_mean[['name', 'purchase_amount']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cc6ac5",
   "metadata": {},
   "source": [
    "### Dica: Remover linhas com valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60150ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se preferir REMOVER linhas com NA em vez de preencher\n",
    "df_drop_na = df_clean.copy()\n",
    "\n",
    "print(f\"Linhas antes: {len(df_drop_na)}\")\n",
    "\n",
    "# Remover linhas com qualquer valor nulo\n",
    "df_drop_na = df_drop_na.dropna()\n",
    "\n",
    "print(f\"Linhas depois: {len(df_drop_na)}\")\n",
    "print(f\"Linhas removidas: {len(df_clean) - len(df_drop_na)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616eb2db",
   "metadata": {},
   "source": [
    "---\n",
    "## Combinando Todas as T√©cnicas\n",
    "\n",
    "### Pipeline completo de limpeza de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "b8bb58e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INICIANDO PIPELINE DE LIMPEZA DE DADOS\n",
      "============================================================\n",
      "\n",
      "1Ô∏è‚É£ Removendo duplicatas...\n",
      "   Linhas removidas: 2\n",
      "\n",
      "2Ô∏è‚É£ Removendo espa√ßos em branco...\n",
      "   Colunas processadas: 4\n",
      "\n",
      "3Ô∏è‚É£ Dividindo colunas...\n",
      "   Novas colunas criadas: email, phone, city, state\n",
      "\n",
      "4Ô∏è‚É£ Padronizando valores...\n",
      "   Coluna 'status' padronizada\n",
      "\n",
      "5Ô∏è‚É£ Preenchendo valores nulos...\n",
      "   Valores nulos preenchidos: 3\n",
      "\n",
      "============================================================\n",
      "‚úÖ PIPELINE CONCLU√çDO!\n",
      "============================================================\n",
      "\n",
      "Dataset final: 10 linhas x 8 colunas\n"
     ]
    }
   ],
   "source": [
    "# Come√ßar do dataset original\n",
    "df_pipeline = df.copy()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"INICIANDO PIPELINE DE LIMPEZA DE DADOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Remover duplicatas\n",
    "print(\"\\n1Ô∏è‚É£ Removendo duplicatas...\")\n",
    "initial_rows = len(df_pipeline)\n",
    "df_pipeline = df_pipeline.drop_duplicates(subset=['customer_id'], keep='first')\n",
    "print(f\"   Linhas removidas: {initial_rows - len(df_pipeline)}\")\n",
    "\n",
    "# 2. Strip de espa√ßos\n",
    "print(\"\\n2Ô∏è‚É£ Removendo espa√ßos em branco...\")\n",
    "string_cols = df_pipeline.select_dtypes(include=['object']).columns\n",
    "for col in string_cols:\n",
    "    df_pipeline[col] = df_pipeline[col].str.strip()\n",
    "print(f\"   Colunas processadas: {len(string_cols)}\")\n",
    "\n",
    "# 3. Splitting de colunas\n",
    "print(\"\\n3Ô∏è‚É£ Dividindo colunas...\")\n",
    "df_pipeline[['email', 'phone']] = df_pipeline['email_phone'].str.split(\n",
    "    '|', expand=True)\n",
    "df_pipeline[['city', 'state']] = df_pipeline['city_state'].str.split(\n",
    "    ', ', expand=True)\n",
    "df_pipeline = df_pipeline.drop(columns=['email_phone', 'city_state'])\n",
    "print(f\"   Novas colunas criadas: email, phone, city, state\")\n",
    "\n",
    "# 4. Replace para padronizar\n",
    "print(\"\\n4Ô∏è‚É£ Padronizando valores...\")\n",
    "df_pipeline['status'] = df_pipeline['status'].replace({\n",
    "    'active': 'Active',\n",
    "    'ACTIVE': 'Active',\n",
    "    'inactive': 'Inactive',\n",
    "    'INACTIVE': 'Inactive'\n",
    "})\n",
    "print(f\"   Coluna 'status' padronizada\")\n",
    "\n",
    "# 5. Fill NA\n",
    "print(\"\\n5Ô∏è‚É£ Preenchendo valores nulos...\")\n",
    "na_count = df_pipeline['purchase_amount'].isnull().sum()\n",
    "df_pipeline['purchase_amount'] = df_pipeline['purchase_amount'].fillna(\n",
    "    df_pipeline['purchase_amount'].median()\n",
    ")\n",
    "print(f\"   Valores nulos preenchidos: {na_count}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ PIPELINE CONCLU√çDO!\")\n",
    "print(\"=\"*60)\n",
    "print(\n",
    "    f\"\\nDataset final: {len(df_pipeline)} linhas x {len(df_pipeline.columns)} colunas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "00f1f26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATASET LIMPO - Primeiras linhas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>name</th>\n",
       "      <th>status</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John Doe</td>\n",
       "      <td>Active</td>\n",
       "      <td>100.50</td>\n",
       "      <td>john@email.com</td>\n",
       "      <td>555-0100</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jane Smith</td>\n",
       "      <td>Active</td>\n",
       "      <td>250.00</td>\n",
       "      <td>jane@email.com</td>\n",
       "      <td>555-0101</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bob Johnson</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>340.20</td>\n",
       "      <td>bob@email.com</td>\n",
       "      <td>555-0102</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Alice Brown</td>\n",
       "      <td>Active</td>\n",
       "      <td>450.75</td>\n",
       "      <td>alice@email.com</td>\n",
       "      <td>555-0103</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Charlie Wilson</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>125.30</td>\n",
       "      <td>charlie@email.com</td>\n",
       "      <td>555-0104</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id            name    status  purchase_amount              email  \\\n",
       "0            1        John Doe    Active           100.50     john@email.com   \n",
       "1            2      Jane Smith    Active           250.00     jane@email.com   \n",
       "3            3     Bob Johnson  Inactive           340.20      bob@email.com   \n",
       "4            4     Alice Brown    Active           450.75    alice@email.com   \n",
       "5            5  Charlie Wilson  Inactive           125.30  charlie@email.com   \n",
       "\n",
       "      phone         city state  \n",
       "0  555-0100     New York    NY  \n",
       "1  555-0101  Los Angeles    CA  \n",
       "3  555-0102      Chicago    IL  \n",
       "4  555-0103      Houston    TX  \n",
       "5  555-0104      Phoenix    AZ  "
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizar dataset limpo\n",
    "print(\"\\nDATASET LIMPO - Primeiras linhas:\")\n",
    "df_pipeline.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5aa065",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
