{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8aed3bb",
   "metadata": {},
   "source": [
    "# Train, Validation e Test Split\n",
    "\n",
    "## Introdução\n",
    "\n",
    "Após implementar um modelo de Machine Learning, surge uma questão fundamental: **como sabemos se nosso modelo realmente funciona bem?** Treinar um modelo e testá-lo nos mesmos dados não é suficiente, pois isso não garante que ele funcionará bem com dados novos que nunca viu antes.\n",
    "\n",
    "A divisão dos dados em conjuntos de **treinamento**, **validação** e **teste** é uma prática essencial para avaliar corretamente o desempenho de modelos de aprendizado de máquina.\n",
    "\n",
    "---\n",
    "\n",
    "## O Problema: Overfitting vs Underfitting\n",
    "\n",
    "### Overfitting (Sobreajuste)\n",
    "\n",
    "**Overfitting** ocorre quando o modelo \"decora\" os dados de treinamento, capturando não apenas os padrões reais, mas também o ruído e peculiaridades específicas daqueles dados.\n",
    "\n",
    "**Características:**\n",
    "- ✅ Performance **excelente** nos dados de treinamento\n",
    "- ❌ Performance **ruim** em dados novos\n",
    "- O modelo é muito específico e não generaliza\n",
    "\n",
    "**Analogia:** É como um aluno que decora as respostas de provas antigas, mas não entende os conceitos. Ele vai bem nas provas antigas, mas falha em questões novas.\n",
    "\n",
    "### Underfitting (Subajuste)\n",
    "\n",
    "**Underfitting** ocorre quando o modelo é muito simples e não consegue capturar os padrões presentes nos dados.\n",
    "\n",
    "**Características:**\n",
    "- ❌ Performance **ruim** nos dados de treinamento\n",
    "- ❌ Performance **ruim** em dados novos\n",
    "- O modelo é simples demais\n",
    "\n",
    "**Analogia:** É como um aluno que não estudou o suficiente e não consegue responder nem as questões básicas.\n",
    "\n",
    "### O Equilíbrio Ideal\n",
    "\n",
    "O objetivo é encontrar o **ponto ideal** onde o modelo:\n",
    "- Aprende os padrões reais dos dados\n",
    "- Generaliza bem para dados novos\n",
    "- Não decora peculiaridades específicas\n",
    "\n",
    "---\n",
    "\n",
    "## Train/Test Split (Divisão Básica)\n",
    "\n",
    "### Conceito\n",
    "\n",
    "A divisão mais simples separa os dados em **dois conjuntos**:\n",
    "\n",
    "1. **Training Set (Conjunto de Treinamento)**: ~70-80% dos dados\n",
    "   - Usado para treinar o modelo\n",
    "   - O modelo aprende os padrões aqui\n",
    "\n",
    "2. **Test Set (Conjunto de Teste)**: ~20-30% dos dados\n",
    "   - Usado **apenas** para avaliar o modelo final\n",
    "   - Simula dados \"do mundo real\" que o modelo nunca viu\n",
    "\n",
    "### Por Que Fazer Isso?\n",
    "\n",
    "**Sem divisão:**\n",
    "```\n",
    "Treina no dataset → Testa no mesmo dataset → R² = 0.99 ✅\n",
    "```\n",
    "Parece ótimo, mas é **enganoso**! O modelo pode estar apenas decorando.\n",
    "\n",
    "**Com divisão:**\n",
    "```\n",
    "Treina no training set → Testa no test set → R² = 0.95 ✅\n",
    "```\n",
    "Agora temos uma medida **real** de como o modelo generaliza.\n",
    "\n",
    "### Proporções Típicas\n",
    "\n",
    "| Tamanho do Dataset | Train | Test |\n",
    "|-------------------|-------|------|\n",
    "| Pequeno (< 1000) | 70% | 30% |\n",
    "| Médio (1k-100k) | 80% | 20% |\n",
    "| Grande (> 100k) | 90% | 10% |\n",
    "\n",
    "**Regra geral:** Quanto mais dados você tem, menor a porcentagem necessária para teste.\n",
    "\n",
    "---\n",
    "\n",
    "## Train/Validation/Test Split (Divisão Completa)\n",
    "\n",
    "### Conceito\n",
    "\n",
    "Para projetos mais robustos, dividimos os dados em **três conjuntos**:\n",
    "\n",
    "1. **Training Set**: ~60-70% dos dados\n",
    "   - Usado para treinar o modelo\n",
    "   - Ajusta os parâmetros (w, b)\n",
    "\n",
    "2. **Validation Set**: ~15-20% dos dados\n",
    "   - Usado para **tunar hiperparâmetros**\n",
    "   - Comparar diferentes modelos\n",
    "   - Detectar overfitting durante o treinamento\n",
    "   - **Não** é usado para treinar\n",
    "\n",
    "3. **Test Set**: ~15-20% dos dados\n",
    "   - Usado **apenas uma vez** no final\n",
    "   - Avaliação final e imparcial\n",
    "   - Simula o desempenho em produção\n",
    "\n",
    "\n",
    "### Por Que Três Conjuntos?\n",
    "\n",
    "**Problema com apenas Train/Test:**\n",
    "- Se usarmos o test set para ajustar hiperparâmetros, ele \"vaza\" informação (data leakage)\n",
    "- O test set deixa de ser imparcial\n",
    "- Podemos fazer overfitting no test set!\n",
    "\n",
    "**Solução com Train/Validation/Test:**\n",
    "- **Validation** é usado para experimentação e ajustes\n",
    "- **Test** permanece \"intocado\" até o final\n",
    "- Temos uma avaliação verdadeiramente imparcial\n",
    "\n",
    "---\n",
    "\n",
    "## Divisão Aleatória vs Estratificada\n",
    "\n",
    "### Divisão Aleatória\n",
    "\n",
    "Seleciona exemplos **aleatoriamente** para cada conjunto.\n",
    "\n",
    "```python\n",
    "np.random.shuffle(data)\n",
    "train = data[:60%]\n",
    "val = data[60%:80%]\n",
    "test = data[80%:]\n",
    "```\n",
    "\n",
    "**Quando usar:**\n",
    "- Dados balanceados\n",
    "- Regressão (valores contínuos)\n",
    "- Datasets grandes\n",
    "\n",
    "### Divisão Estratificada\n",
    "\n",
    "Mantém a **mesma proporção de classes** em todos os conjuntos.\n",
    "\n",
    "**Quando usar:**\n",
    "- Classificação com classes desbalanceadas\n",
    "- Ex: 95% classe A, 5% classe B\n",
    "- Garante que train, val e test tenham ~95%/5%\n",
    "\n",
    "---\n",
    "\n",
    "## Boas Práticas\n",
    "\n",
    "###  O Que Fazer\n",
    "\n",
    "1. **Dividir ANTES de qualquer processamento**\n",
    "   - Normalize depois da divisão\n",
    "   - Evita \"data leakage\"\n",
    "\n",
    "2. **Nunca treinar com dados de validação/teste**\n",
    "   - Validação é apenas para avaliar\n",
    "   - Teste é apenas para avaliação final\n",
    "\n",
    "3. **Manter test set \"sagrado\"**\n",
    "   - Use apenas UMA VEZ no final\n",
    "   - Não ajuste nada baseado nele\n",
    "\n",
    "4. **Shuffle (embaralhar) os dados**\n",
    "   - Evita bias se dados estão ordenados\n",
    "\n",
    "###  O Que NÃO Fazer\n",
    "\n",
    "1. Normalizar antes de dividir (causa data leakage)\n",
    "2. Usar test set para ajustar hiperparâmetros\n",
    "3. Treinar com validation/test set\n",
    "4. Avaliar múltiplas vezes no test set\n",
    "5. Dividir dados temporais aleatoriamente (use divisão temporal)\n",
    "\n",
    "---\n",
    "\n",
    "## Dados Temporais (Time Series)\n",
    "\n",
    "Para dados com componente temporal (preços de ações, vendas ao longo do tempo), **NÃO embaralhe**!\n",
    "\n",
    "**Exemplo:**\n",
    "- Train: Janeiro - Agosto (8 meses)\n",
    "- Validation: Setembro - Outubro (2 meses)\n",
    "- Test: Novembro - Dezembro (2 meses)\n",
    "\n",
    "**Por quê?** \n",
    "- Em produção, você sempre prevê o futuro baseado no passado\n",
    "- Embaralhar cria \"vazamento temporal\" (model sees the future)\n",
    "\n",
    "---\n",
    "\n",
    "## Resumo\n",
    "\n",
    "| Tipo do Dado | Train Set | Validation Set | Test Set |\n",
    "|---------|-----------|----------------|----------|\n",
    "| **Uso** | Treinar modelo | Ajustar hiperparâmetros | Avaliação final |\n",
    "| **Frequência** | Múltiplas vezes | Múltiplas vezes | **Uma vez** |\n",
    "| **Tamanho** | 60-80% | 10-20% | 10-20% |\n",
    "| **Pode treinar?** | ✅ Sim | ❌ Não | ❌ Não |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822bef58",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6718d2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# IMPORTAÇÕES\n",
    "# ============================================================\n",
    "\n",
    "# Biblioteca para cálculo numérico\n",
    "import numpy as np\n",
    "\n",
    "# Biblioteca para visualização\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Função para dividir dados em treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modelo de regressão linear\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Métrica R² (coeficiente de determinação)\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6e8fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# GERAÇÃO DOS DADOS (DATASET SINTÉTICO)\n",
    "# ============================================================\n",
    "\n",
    "# Fixa a semente para garantir reprodutibilidade\n",
    "np.random.seed(42)\n",
    "\n",
    "# Variável independente X (50 pontos entre 0 e 10)\n",
    "X = np.random.rand(50, 1) * 10\n",
    "\n",
    "# Variável dependente y\n",
    "# Relação linear: y = 2.5x + 5 + ruído\n",
    "y = 2.5 * X.ravel() + 5 + np.random.randn(50) * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa92f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ============================================================\n",
    "# CENÁRIO 1 — SEM TRAIN/TEST SPLIT (ERRADO)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n❌ CENÁRIO 1: SEM TRAIN/TEST SPLIT\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Cria o modelo\n",
    "model_sem_split = LinearRegression()\n",
    "\n",
    "# Treina o modelo usando TODOS os dados\n",
    "model_sem_split.fit(X, y)\n",
    "\n",
    "# Faz previsões nos mesmos dados usados no treino\n",
    "y_pred_sem_split = model_sem_split.predict(X)\n",
    "\n",
    "# Calcula o R² usando treino = teste (problema!)\n",
    "r2_sem_split = r2_score(y, y_pred_sem_split)\n",
    "\n",
    "print(f\"R² = {r2_sem_split:.4f}\")\n",
    "print(\"⚠️  Avaliação enganosa: o modelo foi testado nos mesmos dados que treinou!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd27f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# CENÁRIO 2 — COM TRAIN/TEST SPLIT (CORRETO)\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"✅ CENÁRIO 2: COM TRAIN/TEST SPLIT\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Divide os dados:\n",
    "# 70% treino | 30% teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training: {len(X_train)} exemplos | Test: {len(X_test)} exemplos\\n\")\n",
    "\n",
    "# Cria o modelo\n",
    "model_bom = LinearRegression()\n",
    "\n",
    "# Treina APENAS com dados de treino\n",
    "model_bom.fit(X_train, y_train)\n",
    "\n",
    "# Previsões no treino\n",
    "y_train_pred = model_bom.predict(X_train)\n",
    "\n",
    "# Previsões em dados NUNCA vistos (teste)\n",
    "y_test_pred = model_bom.predict(X_test)\n",
    "\n",
    "# Avaliação correta\n",
    "r2_train_bom = r2_score(y_train, y_train_pred)\n",
    "r2_test_bom = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"R² Training: {r2_train_bom:.4f}\")\n",
    "print(f\"R² Test:     {r2_test_bom:.4f}\")\n",
    "print(f\"Diferença:   {abs(r2_train_bom - r2_test_bom):.4f}\")\n",
    "print(\"✨ Modelo generaliza bem!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91aa0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VISUALIZAÇÃO — TRAIN vs TEST (VERSÃO LIMPA)\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Linha contínua para a regressão\n",
    "X_line = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
    "\n",
    "# Paleta azul\n",
    "blue_light = \"#7EC8E3\"\n",
    "blue_dark = \"#1F4E79\"\n",
    "blue_mid = \"#3A7CA5\"\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# GRÁFICO 1 — SEM SPLIT\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "axes[0].scatter(\n",
    "    X, y,\n",
    "    s=90,\n",
    "    color=blue_light,\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "axes[0].plot(\n",
    "    X_line,\n",
    "    model_sem_split.predict(X_line),\n",
    "    color=blue_dark,\n",
    "    linewidth=3\n",
    ")\n",
    "\n",
    "axes[0].set_title(\n",
    "    f\"Sem Train/Test Split\\nR² = {r2_sem_split:.3f}\",\n",
    "    fontsize=13,\n",
    "    fontweight=\"bold\",\n",
    "    color=blue_dark\n",
    ")\n",
    "\n",
    "axes[0].set_xlabel(\"X\")\n",
    "axes[0].set_ylabel(\"y\")\n",
    "axes[0].grid(True, alpha=0.25)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# GRÁFICO 2 — COM SPLIT\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Treino\n",
    "axes[1].scatter(\n",
    "    X_train, y_train,\n",
    "    s=90,\n",
    "    color=blue_mid,\n",
    "    alpha=0.75,\n",
    "    label=\"Treino\"\n",
    ")\n",
    "\n",
    "# Teste\n",
    "axes[1].scatter(\n",
    "    X_test, y_test,\n",
    "    s=90,\n",
    "    color=blue_light,\n",
    "    edgecolor=blue_dark,\n",
    "    linewidth=1.5,\n",
    "    label=\"Teste\"\n",
    ")\n",
    "\n",
    "# Modelo treinado no treino\n",
    "axes[1].plot(\n",
    "    X_line,\n",
    "    model_bom.predict(X_line),\n",
    "    color=blue_dark,\n",
    "    linewidth=3\n",
    ")\n",
    "\n",
    "axes[1].set_title(\n",
    "    f\"Com Train/Test Split\\nTrain={r2_train_bom:.2f} | Test={r2_test_bom:.2f}\",\n",
    "    fontsize=13,\n",
    "    fontweight=\"bold\",\n",
    "    color=blue_dark\n",
    ")\n",
    "\n",
    "axes[1].set_xlabel(\"X\")\n",
    "axes[1].set_ylabel(\"y\")\n",
    "axes[1].legend(frameon=False)\n",
    "axes[1].grid(True, alpha=0.25)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e7e2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
